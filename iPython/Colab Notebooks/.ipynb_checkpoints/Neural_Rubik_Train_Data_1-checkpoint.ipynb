{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HbcwMoAK3OC"
   },
   "source": [
    "# <center> <img src='../../images/fsktm.jpg' width=\"500\" height=\"400\"> </center>\n",
    "# <center> WQD7002 - SCIENCE DATA RESEARCH PROJECT </center>\n",
    "## <center> NEURAL RUBIK’S </center>\n",
    "## <center> Solving Rubik's Cube Using Nueral Network (Hueristic Learning) </center>\n",
    "### <center> Scripted by : Gunasegarran Magadevan (WQD170002) </center>\n",
    "### <center> Supervised by : Dr.Aznul Qalid Md Sabri </center>\n",
    "# <center> <img src=\"../../images/RubiksNeural.jpg\" width=\"500\" height=\"600\"> </center>\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6nffoGtK3OD"
   },
   "source": [
    "### STEP 1 : Installing and upgrading the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 97
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 24649,
     "status": "ok",
     "timestamp": 1556763715620,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "7uK4guNFK3OE",
    "outputId": "abae9ca1-06b4-4bdc-d52b-96b62274b742"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[K     |████████████████████████████████| 61kB 2.9MB/s \n",
      "\u001b[K     |████████████████████████████████| 993kB 3.4MB/s \n",
      "\u001b[?25h  Building wheel for PyDrive (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "# Upgrading the pip package to the latest version\n",
    "!python -m pip install PyHamcrest --upgrade --quiet\n",
    "!python -m pip install tensorflow --upgrade --quiet\n",
    "!python -m pip install rubikai --no-cache-dir --upgrade --quiet\n",
    "!python -m pip install seaborn --no-cache-dir --upgrade --quiet\n",
    "!python -m pip install keras --upgrade --quiet\n",
    "!python -m pip install numpy --upgrade --quiet\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "# Tensorflow package manually through terminal or cmd - https://anaconda.org/conda-forge\n",
    "#conda install -c conda-forge tensorflow\n",
    "#conda install -c conda-forge numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_15z_mbK3OL"
   },
   "source": [
    "### STEP 2 : Importing the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 25844,
     "status": "ok",
     "timestamp": 1556763716836,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "OShbu8YjK3OM",
    "outputId": "7b65b9b9-abc1-451a-818f-f39000692f23"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import rubikai as rubik\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import google.colab.files\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdZBBw3iK3OS"
   },
   "source": [
    "### STEP 3 : Import/Export Using Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5zh8X98RQUbw"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3GIY3i9j8tX"
   },
   "outputs": [],
   "source": [
    "def refresh_gdrive_token():\n",
    "  global auth\n",
    "  global drive\n",
    "  global gauth\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swma4dxb_oN-"
   },
   "outputs": [],
   "source": [
    "SAVE_TO_DRIVE = False\n",
    "\n",
    "def upload_file_to_drive(local_filename, remote_filename=None):\n",
    "  refresh_gdrive_token()\n",
    "  if remote_filename is None:\n",
    "    remote_filename = 'drive_' + local_filename\n",
    "  uploaded = drive.CreateFile({'title': remote_filename})\n",
    "  uploaded.SetContentFile(local_filename)\n",
    "  uploaded.Upload()\n",
    "  return\n",
    "\n",
    "\n",
    "def download_model_from_drive(remote_filename, local_filename=None):\n",
    "  refresh_gdrive_token()\n",
    "  if local_filename is None:\n",
    "    local_filename = 'local_' + remote_filename\n",
    "  file_list = drive.ListFile(\n",
    "      {'q': \"title = '{}'\".format(remote_filename)}).GetList()\n",
    "  if file_list:\n",
    "    file_list[0].GetContentFile(local_filename)\n",
    "    model = keras.models.load_model(local_filename)\n",
    "    return model\n",
    "  else:\n",
    "    print('file not found in drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gotiaTw8Zwcj"
   },
   "outputs": [],
   "source": [
    "# save/load model functions\n",
    "def save_model(model, filename):\n",
    "  global SAVE_TO_DRIVE\n",
    "  if SAVE_TO_DRIVE is True:\n",
    "    model.save(filename)\n",
    "    upload_file_to_drive(filename, filename)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "  return download_model_from_drive(filename, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NPRAYU1IuJwF"
   },
   "source": [
    "### STEP 4 : Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPSskq2p6zqV"
   },
   "source": [
    "Below are functions related to probability vectors. \n",
    "* `create_prob_vector` generates the \"real\" distribution of cube configurations\n",
    "* `convex_combination` returns a convex combination of two vectors\n",
    "* `convex_combination_probabilities` returns a convex combination of the real distribution and the uniform one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXvei0SWr9rc"
   },
   "outputs": [],
   "source": [
    "# Number of states in each distance from goal (taken from http://cube20.org/qtm/)\n",
    "count_vector = np.array([1, 12, 114, 1068, 10011, 93840, 878880, 8221632,\n",
    "                         76843595, 717789576, 6701836858, 62549615248,\n",
    "                         583570100997, 5442351625028, 50729620202582,\n",
    "                         472495678811004, 4393570406220123, 40648181519827392,\n",
    "                         368071526203620348, 3e18, 14e18, 19e18, 7e18, 24e15,\n",
    "                         150000, 36, 3])\n",
    "\n",
    "def create_prob_vector(lower, upper):\n",
    "  vec = count_vector[lower:upper]\n",
    "  return vec / np.sum(vec)\n",
    "\n",
    "\n",
    "def convex_combination(v , u, alpha):\n",
    "  \"\"\" return covex combination of u, v i.e v*alpha + u*(1- alpha) \"\"\"\n",
    "  assert len(u) == len(v), 'u ,v must have same length'\n",
    "  assert 0 <= alpha <= 1, 'alpha must be between 0 and 1'\n",
    "  return np.array(v)*alpha + np.array(u)*(1-alpha)\n",
    "\n",
    "def convex_combination_probabilities(alpha, lower, upper):\n",
    "  \"\"\" \n",
    "  returns convex combination of real probability and uniform distribution\n",
    "  real_probabilites*alpha + uniform*(1- alpha)\n",
    "  \"\"\"\n",
    "  rel_prob = create_prob_vector(lower, upper)\n",
    "  n = len(rel_prob)\n",
    "  uniform = np.ones(n) / n\n",
    "  return convex_combination(rel_prob, uniform, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQCZ4MTz_cFe"
   },
   "source": [
    "### STEP 5 :  Functions for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0fLmKLPtUbQ"
   },
   "outputs": [],
   "source": [
    "def get_features_from_cube(cube):\n",
    "  \"\"\" transforms the cube's array to 1d binary array \"\"\"\n",
    "  binary_array = keras.utils.to_categorical(cube.to_array(), rubik.NUM_FACES)\n",
    "  return binary_array.flatten()\n",
    "\n",
    " \n",
    "def data_generator(cube_layers, max_d, batch_size, p=None):\n",
    "  \"\"\"\n",
    "  generates batches of scrambled cubes data, coupled with the number\n",
    "  of scramble moves per row\n",
    "  \"\"\"\n",
    "  new_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
    "  while True:\n",
    "    data = np.empty((batch_size, new_dim), dtype=np.int8)\n",
    "    labels = np.empty(batch_size, dtype=np.int8)\n",
    "    for i in range(batch_size):\n",
    "      c = rubik.Cube(cube_layers)\n",
    "      d = np.random.choice(np.arange(max_d+1), p=p)\n",
    "      rand_seq = rubik.generate_random_sequence(cube_layers, d)\n",
    "      c.apply(rand_seq)\n",
    "      data[i, :] = get_features_from_cube(c)\n",
    "      labels[i] = d\n",
    "    yield data, labels  \n",
    "\n",
    "\n",
    "def create_dnnregressor(cube_layers, hidden_units, dropout=None,\n",
    "                        optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  creates a fully connected multi-layer perceptron with non-linear activations\n",
    "  to perform regression.\n",
    "  \n",
    "  :param cube_layers: the number of cube layers this model should operate on\n",
    "  :param hidden_units: list of integers specifying how many hidden neurons\n",
    "                       are in each layer\n",
    "  :param dropout: if None, no dropout is used. if a single integer, uses this\n",
    "                  dropout rate after each layer. otherwise, should be a list of\n",
    "                  integers the same length as hidden_units specifying dropout \n",
    "                  rate after each layer\n",
    "  :param optimizer: which (keras) optimizer to use\n",
    "  :param loss: which (keras) loss to use\n",
    "  :returns: a compiled keras.Sequential model\n",
    "  \"\"\"\n",
    "  # input checks\n",
    "  assert hasattr(hidden_units, '__len__'), 'hidden_units must be array-like'\n",
    "  assert len(hidden_units) > 0, 'hidden_units cannot be empty'\n",
    "  if dropout is not None:\n",
    "    if not hasattr(dropout, '__len__'):\n",
    "      dropout = [dropout] * len(hidden_units)\n",
    "    else:\n",
    "      assert len(hidden_units) == len(dropout)\n",
    "  # define some constant model parameters\n",
    "  activation = 'relu'\n",
    "  out_activation = 'relu'\n",
    "  input_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
    "  \n",
    "  # create a sequential model and add the first layer\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Dense(hidden_units[0],\n",
    "                               input_dim=input_dim,\n",
    "                               activation=activation))\n",
    "  if dropout is not None:\n",
    "    model.add(keras.layers.Dropout(dropout[0]))\n",
    "    \n",
    "  # add the rest of the hidden layers\n",
    "  for i in range(1, len(hidden_units)):\n",
    "    model.add(keras.layers.Dense(hidden_units[i], activation=activation))\n",
    "    if dropout is not None:\n",
    "      model.add(keras.layers.Dropout(dropout[i]))\n",
    "\n",
    "  # define the output layer\n",
    "  model.add(keras.layers.Dense(1, activation=out_activation))\n",
    "  model.compile(optimizer=optimizer, loss=loss)\n",
    "  return model\n",
    "\n",
    "\n",
    "def learn_heuristic(layers, max_d, p, steps, epochs, batch_size, hidden_units,\n",
    "                    dropout=None, optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  trains a model with the given config.\n",
    "  \n",
    "  :param layers: number of cube layers\n",
    "  :param max_d: maximum number of scramble steps\n",
    "  :param p: a probability distribution according to which the\n",
    "            scramble steps number is chosen (array of length max_d+1)\n",
    "            (for uniform dist. use None)\n",
    "  :param steps: number of training steps per epoch\n",
    "  :param epochs: number of epochs\n",
    "  :param batch_size: number of cube instances in each training step\n",
    "  :param hidden_units: number of dnn layers and neurons in each layer\n",
    "                       (an array of integers)\n",
    "  :param dropout: same as in create_dnnregressor\n",
    "  :param optimizer: same as in create_dnnregressor\n",
    "  :param loss: same as in create_dnnregressor\n",
    "  :returns: a pair (estimator, history), where estimator is a (trained)\n",
    "            keras model, and history is the training Keras history object\n",
    "  \"\"\"\n",
    "  # set up parameters\n",
    "  c = rubik.Cube(layers)\n",
    "  # initialize the model\n",
    "  estimator = create_dnnregressor(\n",
    "      cube_layers=layers,\n",
    "      hidden_units=hidden_units,\n",
    "      dropout=dropout,\n",
    "      optimizer=optimizer,\n",
    "      loss=loss\n",
    "  )\n",
    "  # train the model\n",
    "  history = estimator.fit_generator(\n",
    "      data_generator(layers, max_d, batch_size, p), steps, epochs\n",
    "  )\n",
    "  return estimator, history\n",
    "\n",
    "\n",
    "def model_to_heuristic(model):\n",
    "  \"\"\" creates a heuristic based on the given keras model \"\"\"\n",
    "  \n",
    "  def _model_h(cube, problem=None):\n",
    "    features = get_features_from_cube(cube)\n",
    "    return model.predict(np.reshape(features, (1, -1)))[0][0]\n",
    "  \n",
    "  return _model_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oi5RHq-eyWcm"
   },
   "source": [
    "### STEP 6 :  Functions for Training\n",
    "\n",
    "## $3\\times3\\times3$\n",
    "We try different network architectures and see which one performs best.\n",
    "\n",
    "The heuristics are then save in the following format:\n",
    "\n",
    "`<layers>_<max_d>_<hidden_1>_..._<hidden_k>.h5`\n",
    "\n",
    "where `hidden_i` is the number of neurons in the `i`'th hidden layer, and `layers` is the number of layers in the cube, and `max_d` is the maximal number of scramble moves.\n",
    "\n",
    "For example, a $3\\times 3 \\times 3$ model with 3 layers of 50 neurons each, and `max_d=8` is saved as: \n",
    "\"`3_8_50_50_50.h5`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cE3Kl1ODI3KU"
   },
   "outputs": [],
   "source": [
    "def get_model_filename(layers, max_d, hidden_units):\n",
    "  delim = '_'\n",
    "  suffix = '.h5'\n",
    "  return delim.join([str(layers), str(max_d)] + \n",
    "                    [str(h) for h in hidden_units]) + suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV_K9kv1AYkG"
   },
   "source": [
    "#### $Definations$\n",
    "* `max_d` (maximal number of scramble moves)\n",
    "* `p` (distribution for the number of moves): $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$, where $\\vec \\rho$ is the real distribution of cube configurations, and $\\vec u$ is the unfirom distribution\n",
    "* `steps` (training steps per epoch)\n",
    "* `epochs` (number of epochs)\n",
    "* `batch_size` (number of examples per training step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-u9iYE7FDz9"
   },
   "outputs": [],
   "source": [
    "layers = 3\n",
    "max_d = 25\n",
    "p = convex_combination_probabilities(0.1, 0, max_d+1)\n",
    "steps = 25\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "dropout = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAonOSAtyPJn"
   },
   "source": [
    "### $\\hat h_1$\n",
    "* `max_d`: `25`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$\n",
    "* `steps`: `25`\n",
    "* `epochs`: `50`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  3 hidden layers with 70, 60, 50 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1839
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1024125,
     "status": "ok",
     "timestamp": 1556764715138,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "ec0kHJF3Aif2",
    "outputId": "108f05de-1d7d-4cde-d062-359014a059f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/50\n",
      "25/25 [==============================] - 19s 764ms/step - loss: 68.6945\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 21s 844ms/step - loss: 28.5614\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 19s 750ms/step - loss: 27.9285\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 19s 777ms/step - loss: 30.8158\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 18s 718ms/step - loss: 25.2992\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 21s 820ms/step - loss: 25.9230\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 20s 781ms/step - loss: 26.4804\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 19s 764ms/step - loss: 23.2775\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 20s 785ms/step - loss: 23.9613\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 21s 852ms/step - loss: 25.2976\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 19s 775ms/step - loss: 25.5320\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 19s 775ms/step - loss: 25.8068\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 19s 756ms/step - loss: 23.5503\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 20s 819ms/step - loss: 23.7554\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 21s 832ms/step - loss: 22.5546\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 18s 736ms/step - loss: 26.6601\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 21s 836ms/step - loss: 27.1307\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 20s 811ms/step - loss: 22.6530\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 20s 808ms/step - loss: 23.2286\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 19s 746ms/step - loss: 26.5660\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 19s 776ms/step - loss: 24.0390\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 19s 748ms/step - loss: 24.7565\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 18s 729ms/step - loss: 18.7812\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 19s 749ms/step - loss: 23.2532\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 18s 733ms/step - loss: 25.3451\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 18s 730ms/step - loss: 22.4067\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 20s 805ms/step - loss: 28.1466\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 19s 766ms/step - loss: 25.5790\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 19s 740ms/step - loss: 26.3889\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 19s 759ms/step - loss: 18.7706\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 20s 807ms/step - loss: 22.0836\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 20s 816ms/step - loss: 21.3965\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 20s 806ms/step - loss: 22.1186\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 19s 742ms/step - loss: 22.6366\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 21s 823ms/step - loss: 24.2947\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 20s 792ms/step - loss: 19.5779\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 19s 767ms/step - loss: 23.0374\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 18s 735ms/step - loss: 21.9973\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 21s 857ms/step - loss: 23.2858\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 20s 785ms/step - loss: 24.3950\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 20s 788ms/step - loss: 23.4067\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 20s 801ms/step - loss: 29.0890\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 21s 831ms/step - loss: 22.9696\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 18s 727ms/step - loss: 19.8875\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 19s 751ms/step - loss: 27.6008\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 19s 762ms/step - loss: 26.5111\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 20s 804ms/step - loss: 21.3175\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 18s 739ms/step - loss: 20.0135\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 20s 807ms/step - loss: 28.4405\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 19s 762ms/step - loss: 24.8965\n"
     ]
    }
   ],
   "source": [
    "hidden_units_1 = [70, 60, 50]\n",
    "m1, history1 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_1, dropout)\n",
    "save_model(m1, get_model_filename(layers, max_d, hidden_units_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Pi4N14Z91SE"
   },
   "source": [
    "### $\\hat h_2$\n",
    "* `max_d`: `25`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ \n",
    "* `steps`: `25`\n",
    "* `epochs`: `50`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  4 hidden layers, 50 neurons per layer\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2005823,
     "status": "ok",
     "timestamp": 1556765696845,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "Pja05ir-GAhI",
    "outputId": "e2b8dfca-e632-4be2-a11a-99cc4604cf96"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 19s 762ms/step - loss: 61.0080\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 20s 804ms/step - loss: 31.3690\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 19s 769ms/step - loss: 31.9688\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 25.9930\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 20s 797ms/step - loss: 27.6971\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 20s 807ms/step - loss: 26.7814\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 20s 790ms/step - loss: 28.1891\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 21s 821ms/step - loss: 24.4861\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 20s 782ms/step - loss: 25.6607\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 21s 830ms/step - loss: 28.9187\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 20s 782ms/step - loss: 27.0117\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 19s 750ms/step - loss: 25.7552\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 22s 871ms/step - loss: 25.2838\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 21s 841ms/step - loss: 23.0889\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 19s 774ms/step - loss: 26.3607\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 20s 786ms/step - loss: 23.5982\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 19s 741ms/step - loss: 22.1964\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 22s 883ms/step - loss: 27.2767\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 19s 744ms/step - loss: 23.5188\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 17s 693ms/step - loss: 21.2974\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 17s 693ms/step - loss: 22.7880\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 21s 827ms/step - loss: 24.6044\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 19s 767ms/step - loss: 23.9076\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 19s 756ms/step - loss: 24.2022\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 19s 769ms/step - loss: 24.6459\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 20s 804ms/step - loss: 26.5672\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 18s 733ms/step - loss: 23.5488\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 18s 740ms/step - loss: 25.4577\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 21s 820ms/step - loss: 23.6725\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 22s 870ms/step - loss: 23.4830\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 19s 762ms/step - loss: 23.4800\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 20s 789ms/step - loss: 21.7338\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 18s 711ms/step - loss: 23.9755\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 22s 870ms/step - loss: 23.2714\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 20s 816ms/step - loss: 26.4638\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 19s 758ms/step - loss: 23.4889\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 18s 714ms/step - loss: 25.1709\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 21s 832ms/step - loss: 21.4334\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 20s 806ms/step - loss: 22.5964\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 18s 734ms/step - loss: 24.2592\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 19s 754ms/step - loss: 25.8393\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 20s 795ms/step - loss: 23.0613\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 19s 770ms/step - loss: 22.5019\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 19s 758ms/step - loss: 25.7304\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 21s 833ms/step - loss: 25.1360\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 21s 820ms/step - loss: 23.7735\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 19s 779ms/step - loss: 24.0968\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 19s 758ms/step - loss: 26.8174\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 20s 805ms/step - loss: 23.6423\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 18s 725ms/step - loss: 23.1062\n"
     ]
    }
   ],
   "source": [
    "hidden_units_2 = [50, 50, 50, 50]\n",
    "m2, history2 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_2, dropout)\n",
    "save_model(m2, get_model_filename(layers, max_d, hidden_units_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2AyPlrIBXOI"
   },
   "source": [
    "### $\\hat h_3$\n",
    "* `max_d`: `25`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ \n",
    "* `steps`: `25`\n",
    "* `epochs`: `50`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  5 hidden layers with 50, 40, 30, 20, 20 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1717
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2979160,
     "status": "ok",
     "timestamp": 1556766670191,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "E4-bTmMcea2Z",
    "outputId": "6389f659-3755-49d3-b0e1-de86eca1aa45"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 20s 781ms/step - loss: 61.0151\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 18s 720ms/step - loss: 29.1080\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 27.1538\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 18s 737ms/step - loss: 25.4819\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 19s 768ms/step - loss: 26.0426\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 17s 697ms/step - loss: 27.3356\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 17s 694ms/step - loss: 28.2580\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 19s 751ms/step - loss: 26.8653\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 18s 735ms/step - loss: 25.8715\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 21s 825ms/step - loss: 25.9203\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 19s 779ms/step - loss: 24.4917\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 18s 731ms/step - loss: 24.3200\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 20s 797ms/step - loss: 24.8120\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 20s 783ms/step - loss: 26.6672\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 19s 768ms/step - loss: 27.6017\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 19s 743ms/step - loss: 22.8659\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 19s 774ms/step - loss: 24.7785\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 20s 804ms/step - loss: 25.3242\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 19s 747ms/step - loss: 23.2984\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 20s 818ms/step - loss: 28.1923\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 19s 772ms/step - loss: 21.2605\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 20s 807ms/step - loss: 27.6111\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 20s 796ms/step - loss: 23.4651\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 18s 737ms/step - loss: 22.1804\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 18s 731ms/step - loss: 25.2510\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 21s 848ms/step - loss: 24.4534\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 21s 858ms/step - loss: 22.7213\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 20s 791ms/step - loss: 22.9881\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 19s 741ms/step - loss: 25.7191\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 21s 829ms/step - loss: 22.2269\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 21s 842ms/step - loss: 26.3382\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 20s 780ms/step - loss: 26.7336\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 20s 808ms/step - loss: 21.9311\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 21s 838ms/step - loss: 22.9609\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 18s 711ms/step - loss: 21.6975\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 22s 860ms/step - loss: 24.9514\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 19s 740ms/step - loss: 22.2769\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 22s 892ms/step - loss: 23.2092\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 19s 766ms/step - loss: 24.7442\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 20s 786ms/step - loss: 31.9169\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 18s 738ms/step - loss: 22.7879\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 21s 853ms/step - loss: 21.4859\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 20s 795ms/step - loss: 23.5329\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 20s 785ms/step - loss: 23.1534\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 20s 785ms/step - loss: 20.5156\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 21s 851ms/step - loss: 20.4648\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 18s 715ms/step - loss: 20.1357\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 18s 714ms/step - loss: 17.3562\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 17s 687ms/step - loss: 20.7781\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 19s 755ms/step - loss: 23.0025\n"
     ]
    }
   ],
   "source": [
    "hidden_units_3 = [50, 40, 30, 20, 20]\n",
    "m3, history3 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_3, dropout)\n",
    "save_model(m3, get_model_filename(layers, max_d, hidden_units_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znxUQ9V37p-p"
   },
   "outputs": [],
   "source": [
    "### STEP 7 :  Plotting the Average Loss VS Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 2980566,
     "status": "ok",
     "timestamp": 1556766671603,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "8UkD5wtR7p-r",
    "outputId": "62980f33-d3fe-4737-c37a-80ca7778bea0"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nNE1r4HQg0DRNa+B0INA0TWvg/h/v7XuJy4gpBgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histories = pd.DataFrame(data={\n",
    "    '$\\hat h_1$': history1.history['loss'],\n",
    "    '$\\hat h_2$': history2.history['loss'],\n",
    "    '$\\hat h_3$': history3.history['loss'],\n",
    "    'epoch': np.arange(1, epochs+1)\n",
    "}).set_index('epoch')\n",
    "sns.lineplot(data=histories);\n",
    "plt.ylabel('average loss');\n",
    "plt.title('Learning Curves');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8LHW8Yp7p-s"
   },
   "outputs": [],
   "source": [
    "histories.to_csv('3_25_training_loss_epoch_1-50.csv')\n",
    "from google.colab import files\n",
    "files.download('3_25_training_loss_epoch_1-50.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZg305-o7p-u"
   },
   "outputs": [],
   "source": [
    "### STEP 8 : Continue Training\n",
    "#### This section loads already trained models and continues to train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsV2CGDh7p-w"
   },
   "outputs": [],
   "source": [
    "layers = 3\n",
    "max_d = 25\n",
    "p = convex_combination_probabilities(0.1, 0, max_d+1)\n",
    "steps = 15\n",
    "epochs = 50\n",
    "batch_size = 8\n",
    "\n",
    "hidden_units_1 = [70, 60, 50]\n",
    "hidden_units_2 = [50, 50, 50, 50]\n",
    "hidden_units_3 = [50, 40, 30, 20, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnd-cpxe7p-x"
   },
   "outputs": [],
   "source": [
    "fn1 = get_model_filename(layers, max_d, hidden_units_1)\n",
    "fn2 = get_model_filename(layers, max_d, hidden_units_2)\n",
    "fn3 = get_model_filename(layers, max_d, hidden_units_3)\n",
    "\n",
    "m1 = load_model(fn1)\n",
    "m2 = load_model(fn2)\n",
    "m3 = load_model(fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "id": "tqslXUN37p-y",
    "outputId": "da82ec29-8f50-4486-979a-faaebbffad5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "15/15 [==============================] - 12s 793ms/step - loss: 22.9925\n",
      "Epoch 2/50\n",
      "15/15 [==============================] - 12s 797ms/step - loss: 20.0467\n",
      "Epoch 3/50\n",
      "15/15 [==============================] - 11s 753ms/step - loss: 19.7549\n",
      "Epoch 4/50\n",
      "15/15 [==============================] - 12s 802ms/step - loss: 21.9052\n",
      "Epoch 5/50\n",
      "11/15 [=====================>........] - ETA: 3s - loss: 21.5157"
     ]
    }
   ],
   "source": [
    "# add some more training for each of the model\n",
    "history1 = m1.fit_generator(\n",
    "    data_generator(layers, max_d, batch_size, p), steps, epochs)\n",
    "save_model(m1, fn1)\n",
    "history2 = m2.fit_generator(\n",
    "    data_generator(layers, max_d, batch_size, p), steps, epochs)\n",
    "save_model(m2, fn2)\n",
    "history3 = m3.fit_generator(\n",
    "    data_generator(layers, max_d, batch_size, p), steps, epochs)\n",
    "save_model(m3, fn3)\n",
    "\n",
    "histories = pd.DataFrame(data={\n",
    "    '$\\hat h_1$': history1.history['loss'],\n",
    "    '$\\hat h_2$': history2.history['loss'],\n",
    "    '$\\hat h_3$': history3.history['loss'],\n",
    "    'epoch': np.arange(101, 101 + epochs)\n",
    "}).set_index('epoch')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Rubik_Train_Data_1.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
