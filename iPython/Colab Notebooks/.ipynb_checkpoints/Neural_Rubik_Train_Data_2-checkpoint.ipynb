{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1HbcwMoAK3OC"
   },
   "source": [
    "# <center> <img src='../../images/fsktm.jpg' width=\"500\" height=\"400\"> </center>\n",
    "# <center> WQD7002 - SCIENCE DATA RESEARCH PROJECT </center>\n",
    "## <center> NEURAL RUBIKâ€™S </center>\n",
    "## <center> Solving Rubik's Cube Using Nueral Network (Hueristic Learning) </center>\n",
    "### <center> Scripted by : Gunasegarran Magadevan (WQD170002) </center>\n",
    "### <center> Supervised by : Dr.Aznul Qalid Md Sabri </center>\n",
    "# <center> <img src=\"../../images/RubiksNeural.jpg\" width=\"500\" height=\"600\"> </center>\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "p6nffoGtK3OD"
   },
   "source": [
    "### STEP 1 : Installing and upgrading the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7uK4guNFK3OE"
   },
   "outputs": [],
   "source": [
    "# Upgrading the pip package to the latest version\n",
    "!python -m pip install PyHamcrest --upgrade --quiet\n",
    "!python -m pip install tensorflow --upgrade --quiet\n",
    "!python -m pip install rubikai --no-cache-dir --upgrade --quiet\n",
    "!python -m pip install seaborn --no-cache-dir --upgrade --quiet\n",
    "!python -m pip install keras --upgrade --quiet\n",
    "!python -m pip install numpy --upgrade --quiet\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "# Tensorflow package manually through terminal or cmd - https://anaconda.org/conda-forge\n",
    "#conda install -c conda-forge tensorflow\n",
    "#conda install -c conda-forge numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "q_15z_mbK3OL"
   },
   "source": [
    "### STEP 2 : Importing the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 32700,
     "status": "ok",
     "timestamp": 1556713960440,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "OShbu8YjK3OM",
    "outputId": "86c8b6c3-d442-4625-c79b-0ac9f523f64a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import rubikai as rubik\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import google.colab.files\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hdZBBw3iK3OS"
   },
   "source": [
    "### STEP 3 : Import/Export Using Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5zh8X98RQUbw"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "v3GIY3i9j8tX"
   },
   "outputs": [],
   "source": [
    "def refresh_gdrive_token():\n",
    "  global auth\n",
    "  global drive\n",
    "  global gauth\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "swma4dxb_oN-"
   },
   "outputs": [],
   "source": [
    "SAVE_TO_DRIVE = True\n",
    "\n",
    "def upload_file_to_drive(local_filename, remote_filename=None):\n",
    "  refresh_gdrive_token()\n",
    "  if remote_filename is None:\n",
    "    remote_filename = 'drive_' + local_filename\n",
    "  uploaded = drive.CreateFile({'title': remote_filename})\n",
    "  uploaded.SetContentFile(local_filename)\n",
    "  uploaded.Upload()\n",
    "  return\n",
    "\n",
    "\n",
    "def download_model_from_drive(remote_filename, local_filename=None):\n",
    "  refresh_gdrive_token()\n",
    "  if local_filename is None:\n",
    "    local_filename = 'local_' + remote_filename\n",
    "  file_list = drive.ListFile(\n",
    "      {'q': \"title = '{}'\".format(remote_filename)}).GetList()\n",
    "  if file_list:\n",
    "    file_list[0].GetContentFile(local_filename)\n",
    "    model = keras.models.load_model(local_filename)\n",
    "    return model\n",
    "  else:\n",
    "    print('file not found in drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "gotiaTw8Zwcj"
   },
   "outputs": [],
   "source": [
    "# save/load model functions\n",
    "def save_model(model, filename):\n",
    "  global SAVE_TO_DRIVE\n",
    "  if SAVE_TO_DRIVE is True:\n",
    "    model.save(filename)\n",
    "    upload_file_to_drive(filename, filename)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "  return download_model_from_drive(filename, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NPRAYU1IuJwF"
   },
   "source": [
    "### STEP 4 : Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPSskq2p6zqV"
   },
   "source": [
    "Below are functions related to probability vectors. \n",
    "* `create_prob_vector` generates the \"real\" distribution of cube configurations\n",
    "* `convex_combination` returns a convex combination of two vectors\n",
    "* `convex_combination_probabilities` returns a convex combination of the real distribution and the uniform one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pXvei0SWr9rc"
   },
   "outputs": [],
   "source": [
    "# Number of states in each distance from goal (taken from http://cube20.org/qtm/)\n",
    "count_vector = np.array([1, 12, 114, 1068, 10011, 93840, 878880, 8221632,\n",
    "                         76843595, 717789576, 6701836858, 62549615248,\n",
    "                         583570100997, 5442351625028, 50729620202582,\n",
    "                         472495678811004, 4393570406220123, 40648181519827392,\n",
    "                         368071526203620348, 3e18, 14e18, 19e18, 7e18, 24e15,\n",
    "                         150000, 36, 3])\n",
    "\n",
    "def create_prob_vector(lower, upper):\n",
    "  vec = count_vector[lower:upper]\n",
    "  return vec / np.sum(vec)\n",
    "\n",
    "\n",
    "def convex_combination(v , u, alpha):\n",
    "  \"\"\" return covex combination of u, v i.e v*alpha + u*(1- alpha) \"\"\"\n",
    "  assert len(u) == len(v), 'u ,v must have same length'\n",
    "  assert 0 <= alpha <= 1, 'alpha must be between 0 and 1'\n",
    "  return np.array(v)*alpha + np.array(u)*(1-alpha)\n",
    "\n",
    "def convex_combination_probabilities(alpha, lower, upper):\n",
    "  \"\"\" \n",
    "  returns convex combination of real probability and uniform distribution\n",
    "  real_probabilites*alpha + uniform*(1- alpha)\n",
    "  \"\"\"\n",
    "  rel_prob = create_prob_vector(lower, upper)\n",
    "  n = len(rel_prob)\n",
    "  uniform = np.ones(n) / n\n",
    "  return convex_combination(rel_prob, uniform, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQCZ4MTz_cFe"
   },
   "source": [
    "### STEP 5 :  Functions for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "u0fLmKLPtUbQ"
   },
   "outputs": [],
   "source": [
    "def get_features_from_cube(cube):\n",
    "  \"\"\" transforms the cube's array to 1d binary array \"\"\"\n",
    "  binary_array = keras.utils.to_categorical(cube.to_array(), rubik.NUM_FACES)\n",
    "  return binary_array.flatten()\n",
    "\n",
    " \n",
    "def data_generator(cube_layers, max_d, batch_size, p=None):\n",
    "  \"\"\"\n",
    "  generates batches of scrambled cubes data, coupled with the number\n",
    "  of scramble moves per row\n",
    "  \"\"\"\n",
    "  new_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
    "  while True:\n",
    "    data = np.empty((batch_size, new_dim), dtype=np.int8)\n",
    "    labels = np.empty(batch_size, dtype=np.int8)\n",
    "    for i in range(batch_size):\n",
    "      c = rubik.Cube(cube_layers)\n",
    "      d = np.random.choice(np.arange(max_d+1), p=p)\n",
    "      rand_seq = rubik.generate_random_sequence(cube_layers, d)\n",
    "      c.apply(rand_seq)\n",
    "      data[i, :] = get_features_from_cube(c)\n",
    "      labels[i] = d\n",
    "    yield data, labels  \n",
    "\n",
    "\n",
    "def create_dnnregressor(cube_layers, hidden_units, dropout=None,\n",
    "                        optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  creates a fully connected multi-layer perceptron with non-linear activations\n",
    "  to perform regression.\n",
    "  \n",
    "  :param cube_layers: the number of cube layers this model should operate on\n",
    "  :param hidden_units: list of integers specifying how many hidden neurons\n",
    "                       are in each layer\n",
    "  :param dropout: if None, no dropout is used. if a single integer, uses this\n",
    "                  dropout rate after each layer. otherwise, should be a list of\n",
    "                  integers the same length as hidden_units specifying dropout \n",
    "                  rate after each layer\n",
    "  :param optimizer: which (keras) optimizer to use\n",
    "  :param loss: which (keras) loss to use\n",
    "  :returns: a compiled keras.Sequential model\n",
    "  \"\"\"\n",
    "  # input checks\n",
    "  assert hasattr(hidden_units, '__len__'), 'hidden_units must be array-like'\n",
    "  assert len(hidden_units) > 0, 'hidden_units cannot be empty'\n",
    "  if dropout is not None:\n",
    "    if not hasattr(dropout, '__len__'):\n",
    "      dropout = [dropout] * len(hidden_units)\n",
    "    else:\n",
    "      assert len(hidden_units) == len(dropout)\n",
    "  # define some constant model parameters\n",
    "  activation = 'relu'\n",
    "  out_activation = 'relu'\n",
    "  input_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
    "  \n",
    "  # create a sequential model and add the first layer\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Dense(hidden_units[0],\n",
    "                               input_dim=input_dim,\n",
    "                               activation=activation))\n",
    "  if dropout is not None:\n",
    "    model.add(keras.layers.Dropout(dropout[0]))\n",
    "    \n",
    "  # add the rest of the hidden layers\n",
    "  for i in range(1, len(hidden_units)):\n",
    "    model.add(keras.layers.Dense(hidden_units[i], activation=activation))\n",
    "    if dropout is not None:\n",
    "      model.add(keras.layers.Dropout(dropout[i]))\n",
    "\n",
    "  # define the output layer\n",
    "  model.add(keras.layers.Dense(1, activation=out_activation))\n",
    "  model.compile(optimizer=optimizer, loss=loss)\n",
    "  return model\n",
    "\n",
    "\n",
    "def learn_heuristic(layers, max_d, p, steps, epochs, batch_size, hidden_units,\n",
    "                    dropout=None, optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  trains a model with the given config.\n",
    "  \n",
    "  :param layers: number of cube layers\n",
    "  :param max_d: maximum number of scramble steps\n",
    "  :param p: a probability distribution according to which the\n",
    "            scramble steps number is chosen (array of length max_d+1)\n",
    "            (for uniform dist. use None)\n",
    "  :param steps: number of training steps per epoch\n",
    "  :param epochs: number of epochs\n",
    "  :param batch_size: number of cube instances in each training step\n",
    "  :param hidden_units: number of dnn layers and neurons in each layer\n",
    "                       (an array of integers)\n",
    "  :param dropout: same as in create_dnnregressor\n",
    "  :param optimizer: same as in create_dnnregressor\n",
    "  :param loss: same as in create_dnnregressor\n",
    "  :returns: a pair (estimator, history), where estimator is a (trained)\n",
    "            keras model, and history is the training Keras history object\n",
    "  \"\"\"\n",
    "  # set up parameters\n",
    "  c = rubik.Cube(layers)\n",
    "  # initialize the model\n",
    "  estimator = create_dnnregressor(\n",
    "      cube_layers=layers,\n",
    "      hidden_units=hidden_units,\n",
    "      dropout=dropout,\n",
    "      optimizer=optimizer,\n",
    "      loss=loss\n",
    "  )\n",
    "  # train the model\n",
    "  history = estimator.fit_generator(\n",
    "      data_generator(layers, max_d, batch_size, p), steps, epochs\n",
    "  )\n",
    "  return estimator, history\n",
    "\n",
    "\n",
    "def model_to_heuristic(model):\n",
    "  \"\"\" creates a heuristic based on the given keras model \"\"\"\n",
    "  \n",
    "  def _model_h(cube, problem=None):\n",
    "    features = get_features_from_cube(cube)\n",
    "    return model.predict(np.reshape(features, (1, -1)))[0][0]\n",
    "  \n",
    "  return _model_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oi5RHq-eyWcm"
   },
   "source": [
    "### STEP 6 :  Functions for Training\n",
    "\n",
    "## $3\\times3\\times3$\n",
    "We try different network architectures and see which one performs best.\n",
    "\n",
    "The heuristics are then save in the following format:\n",
    "\n",
    "`<layers>_<max_d>_<hidden_1>_..._<hidden_k>.h5`\n",
    "\n",
    "where `hidden_i` is the number of neurons in the `i`'th hidden layer, and `layers` is the number of layers in the cube, and `max_d` is the maximal number of scramble moves.\n",
    "\n",
    "For example, a $3\\times 3 \\times 3$ model with 3 layers of 50 neurons each, and `max_d=8` is saved as: \n",
    "\"`3_8_50_50_50.h5`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cE3Kl1ODI3KU"
   },
   "outputs": [],
   "source": [
    "def get_model_filename(layers, max_d, hidden_units):\n",
    "  delim = '_'\n",
    "  suffix = '.h5'\n",
    "  return delim.join([str(layers), str(max_d)] + \n",
    "                    [str(h) for h in hidden_units]) + suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV_K9kv1AYkG"
   },
   "source": [
    "#### $Definations$\n",
    "* `max_d` (maximal number of scramble moves)\n",
    "* `p` (distribution for the number of moves): $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$, where $\\vec \\rho$ is the real distribution of cube configurations, and $\\vec u$ is the unfirom distribution\n",
    "* `steps` (training steps per epoch)\n",
    "* `epochs` (number of epochs)\n",
    "* `batch_size` (number of examples per training step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "q-u9iYE7FDz9"
   },
   "outputs": [],
   "source": [
    "layers = 3\n",
    "max_d = 25\n",
    "p = convex_combination_probabilities(0.1, 0, max_d+1)\n",
    "steps = 50\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "dropout = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAonOSAtyPJn"
   },
   "source": [
    "### $\\hat h_1$\n",
    "* `max_d`: `25`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$\n",
    "* `steps`: `25`\n",
    "* `epochs`: `50`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  3 hidden layers with 70, 60, 50 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3539
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4326,
     "status": "ok",
     "timestamp": 1556746831788,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "ec0kHJF3Aif2",
    "outputId": "1c348134-19f8-4ab3-bf3e-be46a207d892"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Epoch 1/100\n",
      "50/50 [==============================] - 53s 1s/step - loss: 46.7392\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 29.0131\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 27.0962\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 28.1960\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 73s 1s/step - loss: 26.7194\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 23.6888\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 25.3831\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 23.6738\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 26.9065\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 74s 1s/step - loss: 21.3895\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 67s 1s/step - loss: 25.2366\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 69s 1s/step - loss: 25.1186\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 24.0869\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 24.5341\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 22.4076\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 69s 1s/step - loss: 24.0561\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 67s 1s/step - loss: 20.5788\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 67s 1s/step - loss: 22.3801\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 23.1348\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 23.3568\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 69s 1s/step - loss: 22.9421\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 67s 1s/step - loss: 21.9459\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 73s 1s/step - loss: 24.8039\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 69s 1s/step - loss: 22.7917\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 24.4428\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 21.4073\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 23.8059\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 22.5346\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 69s 1s/step - loss: 22.4980\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 22.2547\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 65s 1s/step - loss: 22.5829\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 21.7393\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 64s 1s/step - loss: 22.7906\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 22.5099\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 22.6702\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 23.2272\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 73s 1s/step - loss: 20.4588\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 24.0939\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 22.1752\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 69s 1s/step - loss: 22.3623\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 22.1258\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 22.2837\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 22.5357\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 65s 1s/step - loss: 22.9237\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 23.4719\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 23.1562\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 23.3485\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 20.3849\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 20.7237\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 69s 1s/step - loss: 24.6970\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 21.7324\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 71s 1s/step - loss: 23.4093\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 20.0055\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 20.7406\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 67s 1s/step - loss: 22.5806\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 21.2736\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 22.9200\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 21.7556\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 22.7467\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 19.9551\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 22.2953\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 21.8250\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 68s 1s/step - loss: 21.2032\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 23.1574\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 72s 1s/step - loss: 21.2032\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 20.7458\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 67s 1s/step - loss: 23.4375\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 73s 1s/step - loss: 23.9412\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 66s 1s/step - loss: 23.1729\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 70s 1s/step - loss: 21.9317\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 63s 1s/step - loss: 24.9779\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 21.2835\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 39s 778ms/step - loss: 22.0106\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 40s 797ms/step - loss: 22.3890\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 21.4055\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 38s 761ms/step - loss: 24.3918\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 40s 792ms/step - loss: 21.0642\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 23.2893\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 21.7968\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 37s 734ms/step - loss: 20.6597\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 39s 770ms/step - loss: 21.7996\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 20.4977\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 37s 745ms/step - loss: 20.9271\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 39s 770ms/step - loss: 22.0440\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 38s 761ms/step - loss: 22.6533\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 20.5759\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 38s 753ms/step - loss: 21.0846\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 41s 817ms/step - loss: 21.6516\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 39s 788ms/step - loss: 24.9107\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 40s 801ms/step - loss: 22.8283\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 19.2105\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 39s 775ms/step - loss: 20.9626\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 23.0416\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 40s 806ms/step - loss: 20.9609\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 40s 792ms/step - loss: 22.5240\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 22.6809\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 21.9694\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 41s 814ms/step - loss: 23.3114\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 19.5904\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 38s 765ms/step - loss: 19.8418\n"
     ]
    }
   ],
   "source": [
    "hidden_units_1 = [70, 60, 50]\n",
    "m1, history1 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_1, dropout)\n",
    "save_model(m1, get_model_filename(layers, max_d, hidden_units_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Pi4N14Z91SE"
   },
   "source": [
    "### $\\hat h_2$\n",
    "* `max_d`: `25`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ \n",
    "* `steps`: `25`\n",
    "* `epochs`: `50`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  4 hidden layers, 50 neurons per layer\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 294,
     "status": "ok",
     "timestamp": 1556746831790,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "Pja05ir-GAhI",
    "outputId": "0530d280-ac84-4969-b0cc-6792ad0b0bdb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 49.3400\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 40s 799ms/step - loss: 31.4605\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 38s 754ms/step - loss: 25.1128\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 40s 799ms/step - loss: 27.3362\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 27.2760\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 24.3171\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 22.0919\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 24.7953\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 24.3289\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 40s 803ms/step - loss: 24.4797\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 24.3663\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 26.3187\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 24.3735\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 43s 855ms/step - loss: 22.8172\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 36s 721ms/step - loss: 20.4139\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 39s 786ms/step - loss: 20.6518\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 20.5823\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 36s 724ms/step - loss: 22.9352\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 41s 812ms/step - loss: 23.4952\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 39s 781ms/step - loss: 23.8046\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 37s 748ms/step - loss: 21.5020\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 39s 773ms/step - loss: 25.5089\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 40s 792ms/step - loss: 24.7934\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 22.0413\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 39s 779ms/step - loss: 20.4770\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 22.6502\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 40s 799ms/step - loss: 24.2504\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 37s 740ms/step - loss: 20.9519\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 21.7892\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 21.9911\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 38s 754ms/step - loss: 21.6158\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 38s 753ms/step - loss: 20.6619\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 39s 771ms/step - loss: 23.8779\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 36s 713ms/step - loss: 21.4932\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 21.0619\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 37s 747ms/step - loss: 21.9972\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 23.1130\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 40s 808ms/step - loss: 22.4170\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 21.9905\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 19.8616\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 22.5710\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 22.1465\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 21.9014\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 40s 807ms/step - loss: 20.1232\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 22.8043\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 40s 804ms/step - loss: 21.3634\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 23.1747\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 23.4272\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 19.6934\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 24.1902\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 39s 781ms/step - loss: 22.4211\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 40s 793ms/step - loss: 19.1559\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 22.4055\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 42s 847ms/step - loss: 24.7941\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 37s 733ms/step - loss: 20.2480\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 39s 779ms/step - loss: 21.9312\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 22.4314\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 18.6271\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 24.0089\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 41s 815ms/step - loss: 20.6792\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 21.4592\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 39s 773ms/step - loss: 21.7205\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 40s 802ms/step - loss: 20.6257\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 23.1779\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 23.3364\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 41s 822ms/step - loss: 20.9583\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 18.9515\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 22.2331\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 20.6121\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 40s 802ms/step - loss: 22.1784\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 24.8692\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 41s 816ms/step - loss: 23.1718\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 39s 786ms/step - loss: 22.4507\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 40s 805ms/step - loss: 20.8594\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 39s 778ms/step - loss: 22.0557\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 20.9365\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 41s 811ms/step - loss: 23.4494\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 41s 813ms/step - loss: 20.5615\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 38s 753ms/step - loss: 21.7489\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 36s 719ms/step - loss: 21.4070\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 39s 781ms/step - loss: 22.5389\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 41s 816ms/step - loss: 22.8686\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 39s 775ms/step - loss: 22.3291\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 23.4738\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 41s 829ms/step - loss: 22.2457\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 39s 776ms/step - loss: 21.6201\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 39s 778ms/step - loss: 20.7449\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 22.5075\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 42s 841ms/step - loss: 22.2579\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 19.4321\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 40s 799ms/step - loss: 23.1063\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 21.7444\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 23.1744\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 22.9544\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 39s 783ms/step - loss: 21.9979\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 38s 767ms/step - loss: 20.6053\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 22.3298\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 20.4506\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 40s 807ms/step - loss: 20.3897\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 38s 750ms/step - loss: 24.0295\n"
     ]
    }
   ],
   "source": [
    "hidden_units_2 = [50, 50, 50, 50]\n",
    "m2, history2 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_2, dropout)\n",
    "save_model(m2, get_model_filename(layers, max_d, hidden_units_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2AyPlrIBXOI"
   },
   "source": [
    "### $\\hat h_3$\n",
    "* `max_d`: `25`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ \n",
    "* `steps`: `25`\n",
    "* `epochs`: `50`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  5 hidden layers with 50, 40, 30, 20, 20 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 164,
     "status": "ok",
     "timestamp": 1556746831791,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "E4-bTmMcea2Z",
    "outputId": "e778fd27-146b-4c35-bb88-2e7c48499b01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "50/50 [==============================] - 39s 784ms/step - loss: 51.5660\n",
      "Epoch 2/100\n",
      "50/50 [==============================] - 39s 785ms/step - loss: 29.6884\n",
      "Epoch 3/100\n",
      "50/50 [==============================] - 40s 803ms/step - loss: 28.2388\n",
      "Epoch 4/100\n",
      "50/50 [==============================] - 38s 766ms/step - loss: 26.2936\n",
      "Epoch 5/100\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 21.4178\n",
      "Epoch 6/100\n",
      "50/50 [==============================] - 38s 760ms/step - loss: 20.8483\n",
      "Epoch 7/100\n",
      "50/50 [==============================] - 40s 804ms/step - loss: 24.7631\n",
      "Epoch 8/100\n",
      "50/50 [==============================] - 36s 723ms/step - loss: 24.6571\n",
      "Epoch 9/100\n",
      "50/50 [==============================] - 37s 750ms/step - loss: 22.3276\n",
      "Epoch 10/100\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 22.9880\n",
      "Epoch 11/100\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 24.6180\n",
      "Epoch 12/100\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 22.9033\n",
      "Epoch 13/100\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 22.5603\n",
      "Epoch 14/100\n",
      "50/50 [==============================] - 41s 817ms/step - loss: 25.6912\n",
      "Epoch 15/100\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 24.3819\n",
      "Epoch 16/100\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 23.0349\n",
      "Epoch 17/100\n",
      "50/50 [==============================] - 38s 755ms/step - loss: 23.8688\n",
      "Epoch 18/100\n",
      "50/50 [==============================] - 39s 776ms/step - loss: 22.9475\n",
      "Epoch 19/100\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 21.0498\n",
      "Epoch 20/100\n",
      "50/50 [==============================] - 40s 799ms/step - loss: 22.8731\n",
      "Epoch 21/100\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 24.1868\n",
      "Epoch 22/100\n",
      "50/50 [==============================] - 40s 806ms/step - loss: 22.4683\n",
      "Epoch 23/100\n",
      "50/50 [==============================] - 38s 758ms/step - loss: 24.7105\n",
      "Epoch 24/100\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 22.9990\n",
      "Epoch 25/100\n",
      "50/50 [==============================] - 36s 720ms/step - loss: 24.0866\n",
      "Epoch 26/100\n",
      "50/50 [==============================] - 42s 838ms/step - loss: 28.0223\n",
      "Epoch 27/100\n",
      "50/50 [==============================] - 39s 777ms/step - loss: 24.0385\n",
      "Epoch 28/100\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 22.2837\n",
      "Epoch 29/100\n",
      "50/50 [==============================] - 39s 775ms/step - loss: 21.3659\n",
      "Epoch 30/100\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 22.7590\n",
      "Epoch 31/100\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 22.4576\n",
      "Epoch 32/100\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 21.8033\n",
      "Epoch 33/100\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 23.0961\n",
      "Epoch 34/100\n",
      "50/50 [==============================] - 41s 820ms/step - loss: 23.0405\n",
      "Epoch 35/100\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 23.6829\n",
      "Epoch 36/100\n",
      "50/50 [==============================] - 39s 772ms/step - loss: 20.9318\n",
      "Epoch 37/100\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 21.7895\n",
      "Epoch 38/100\n",
      "50/50 [==============================] - 37s 739ms/step - loss: 21.7192\n",
      "Epoch 39/100\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 22.9058\n",
      "Epoch 40/100\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 25.2218\n",
      "Epoch 41/100\n",
      "50/50 [==============================] - 38s 765ms/step - loss: 22.4740\n",
      "Epoch 42/100\n",
      "50/50 [==============================] - 40s 806ms/step - loss: 21.7445\n",
      "Epoch 43/100\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 22.9287\n",
      "Epoch 44/100\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 23.3034\n",
      "Epoch 45/100\n",
      "50/50 [==============================] - 40s 808ms/step - loss: 25.0841\n",
      "Epoch 46/100\n",
      "50/50 [==============================] - 39s 771ms/step - loss: 22.8078\n",
      "Epoch 47/100\n",
      "50/50 [==============================] - 39s 787ms/step - loss: 20.4091\n",
      "Epoch 48/100\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 21.7437\n",
      "Epoch 49/100\n",
      "50/50 [==============================] - 39s 779ms/step - loss: 21.5393\n",
      "Epoch 50/100\n",
      "50/50 [==============================] - 38s 751ms/step - loss: 20.6977\n",
      "Epoch 51/100\n",
      "50/50 [==============================] - 41s 814ms/step - loss: 23.2653\n",
      "Epoch 52/100\n",
      "50/50 [==============================] - 36s 727ms/step - loss: 23.2812\n",
      "Epoch 53/100\n",
      "50/50 [==============================] - 42s 836ms/step - loss: 23.2251\n",
      "Epoch 54/100\n",
      "50/50 [==============================] - 36s 718ms/step - loss: 19.9670\n",
      "Epoch 55/100\n",
      "50/50 [==============================] - 39s 772ms/step - loss: 19.1803\n",
      "Epoch 56/100\n",
      "50/50 [==============================] - 38s 769ms/step - loss: 24.2845\n",
      "Epoch 57/100\n",
      "50/50 [==============================] - 41s 814ms/step - loss: 23.0437\n",
      "Epoch 58/100\n",
      "50/50 [==============================] - 41s 820ms/step - loss: 24.3989\n",
      "Epoch 59/100\n",
      "50/50 [==============================] - 40s 796ms/step - loss: 21.9878\n",
      "Epoch 60/100\n",
      "50/50 [==============================] - 37s 742ms/step - loss: 20.8971\n",
      "Epoch 61/100\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 23.6896\n",
      "Epoch 62/100\n",
      "50/50 [==============================] - 39s 788ms/step - loss: 24.8188\n",
      "Epoch 63/100\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 23.6723\n",
      "Epoch 64/100\n",
      "50/50 [==============================] - 38s 756ms/step - loss: 22.3031\n",
      "Epoch 65/100\n",
      "50/50 [==============================] - 38s 759ms/step - loss: 24.7721\n",
      "Epoch 66/100\n",
      "50/50 [==============================] - 41s 817ms/step - loss: 23.3682\n",
      "Epoch 67/100\n",
      "50/50 [==============================] - 39s 773ms/step - loss: 20.4020\n",
      "Epoch 68/100\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 20.7223\n",
      "Epoch 69/100\n",
      "50/50 [==============================] - 37s 744ms/step - loss: 20.4677\n",
      "Epoch 70/100\n",
      "50/50 [==============================] - 40s 791ms/step - loss: 22.7128\n",
      "Epoch 71/100\n",
      "50/50 [==============================] - 36s 710ms/step - loss: 19.8735\n",
      "Epoch 72/100\n",
      "50/50 [==============================] - 40s 802ms/step - loss: 23.7067\n",
      "Epoch 73/100\n",
      "50/50 [==============================] - 38s 763ms/step - loss: 23.0669\n",
      "Epoch 74/100\n",
      "50/50 [==============================] - 39s 789ms/step - loss: 21.4090\n",
      "Epoch 75/100\n",
      "50/50 [==============================] - 37s 732ms/step - loss: 20.9713\n",
      "Epoch 76/100\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 21.2282\n",
      "Epoch 77/100\n",
      "50/50 [==============================] - 36s 722ms/step - loss: 21.3784\n",
      "Epoch 78/100\n",
      "50/50 [==============================] - 40s 809ms/step - loss: 24.7561\n",
      "Epoch 79/100\n",
      "50/50 [==============================] - 37s 749ms/step - loss: 22.8400\n",
      "Epoch 80/100\n",
      "50/50 [==============================] - 38s 764ms/step - loss: 23.5909\n",
      "Epoch 81/100\n",
      "50/50 [==============================] - 37s 735ms/step - loss: 21.5469\n",
      "Epoch 82/100\n",
      "50/50 [==============================] - 40s 808ms/step - loss: 22.5223\n",
      "Epoch 83/100\n",
      "50/50 [==============================] - 38s 757ms/step - loss: 23.0558\n",
      "Epoch 84/100\n",
      "50/50 [==============================] - 40s 794ms/step - loss: 20.7582\n",
      "Epoch 85/100\n",
      "50/50 [==============================] - 39s 779ms/step - loss: 20.6100\n",
      "Epoch 86/100\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 22.1462\n",
      "Epoch 87/100\n",
      "50/50 [==============================] - 36s 725ms/step - loss: 23.6844\n",
      "Epoch 88/100\n",
      "50/50 [==============================] - 40s 801ms/step - loss: 25.0217\n",
      "Epoch 89/100\n",
      "50/50 [==============================] - 39s 775ms/step - loss: 20.2042\n",
      "Epoch 90/100\n",
      "50/50 [==============================] - 38s 768ms/step - loss: 22.0490\n",
      "Epoch 91/100\n",
      "50/50 [==============================] - 39s 780ms/step - loss: 21.2353\n",
      "Epoch 92/100\n",
      "50/50 [==============================] - 39s 782ms/step - loss: 21.0205\n",
      "Epoch 93/100\n",
      "50/50 [==============================] - 39s 772ms/step - loss: 21.7535\n",
      "Epoch 94/100\n",
      "50/50 [==============================] - 39s 774ms/step - loss: 21.8146\n",
      "Epoch 95/100\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 19.8130\n",
      "Epoch 96/100\n",
      "50/50 [==============================] - 37s 741ms/step - loss: 21.6600\n",
      "Epoch 97/100\n",
      "50/50 [==============================] - 40s 798ms/step - loss: 22.4638\n",
      "Epoch 98/100\n",
      "50/50 [==============================] - 39s 775ms/step - loss: 22.4313\n",
      "Epoch 99/100\n",
      "50/50 [==============================] - 38s 767ms/step - loss: 21.4480\n",
      "Epoch 100/100\n",
      "50/50 [==============================] - 38s 762ms/step - loss: 21.5664\n"
     ]
    }
   ],
   "source": [
    "hidden_units_3 = [50, 40, 30, 20, 20]\n",
    "m3, history3 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_3, dropout)\n",
    "save_model(m3, get_model_filename(layers, max_d, hidden_units_3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "znxUQ9V37p-p"
   },
   "outputs": [],
   "source": [
    "### STEP 7 :  Plotting the Average Loss VS Learning Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 295
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1556746831794,
     "user": {
      "displayName": "Gunasegarran Magadevan",
      "photoUrl": "https://lh6.googleusercontent.com/-MbOdY-Y6KeU/AAAAAAAAAAI/AAAAAAAAAr0/aVltPfbFr5U/s64/photo.jpg",
      "userId": "14938348637033574038"
     },
     "user_tz": -480
    },
    "id": "8UkD5wtR7p-r",
    "outputId": "edca8d50-ae84-448f-cd33-158c858baf5e"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEWCAYAAABrDZDcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nqKi0c/4fggvTub2Xq5oAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "histories = pd.DataFrame(data={\n",
    "    '$\\hat h_1$': history1.history['loss'],\n",
    "    '$\\hat h_2$': history2.history['loss'],\n",
    "    '$\\hat h_3$': history3.history['loss'],\n",
    "    'epoch': np.arange(1, epochs+1)\n",
    "}).set_index('epoch')\n",
    "sns.lineplot(data=histories);\n",
    "plt.ylabel('average loss');\n",
    "plt.title('Learning Curves');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "s8LHW8Yp7p-s"
   },
   "outputs": [],
   "source": [
    "histories.to_csv('3_25_training_loss_epoch_1-100.csv')\n",
    "from google.colab import files\n",
    "files.download('3_25_training_loss_epoch_1-100.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "kZg305-o7p-u"
   },
   "outputs": [],
   "source": [
    "### STEP 8 : Continue Training\n",
    "#### This section loads already trained models and continues to train them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "xsV2CGDh7p-w"
   },
   "outputs": [],
   "source": [
    "layers = 3\n",
    "max_d = 25\n",
    "p = convex_combination_probabilities(0.1, 0, max_d+1)\n",
    "steps = 30\n",
    "epochs = 100\n",
    "batch_size = 8\n",
    "\n",
    "hidden_units_1 = [70, 60, 50]\n",
    "hidden_units_2 = [50, 50, 50, 50]\n",
    "hidden_units_3 = [50, 40, 30, 20, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cnd-cpxe7p-x"
   },
   "outputs": [],
   "source": [
    "fn1 = get_model_filename(layers, max_d, hidden_units_1)\n",
    "fn2 = get_model_filename(layers, max_d, hidden_units_2)\n",
    "fn3 = get_model_filename(layers, max_d, hidden_units_3)\n",
    "\n",
    "m1 = load_model(fn1)\n",
    "m2 = load_model(fn2)\n",
    "m3 = load_model(fn3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "tqslXUN37p-y"
   },
   "outputs": [],
   "source": [
    "# add some more training for each of the model\n",
    "history1 = m1.fit_generator(\n",
    "    data_generator(layers, max_d, batch_size, p), steps, epochs)\n",
    "save_model(m1, fn1)\n",
    "history2 = m2.fit_generator(\n",
    "    data_generator(layers, max_d, batch_size, p), steps, epochs)\n",
    "save_model(m2, fn2)\n",
    "history3 = m3.fit_generator(\n",
    "    data_generator(layers, max_d, batch_size, p), steps, epochs)\n",
    "save_model(m3, fn3)\n",
    "\n",
    "histories = pd.DataFrame(data={\n",
    "    '$\\hat h_1$': history1.history['loss'],\n",
    "    '$\\hat h_2$': history2.history['loss'],\n",
    "    '$\\hat h_3$': history3.history['loss'],\n",
    "    'epoch': np.arange(101, 101 + epochs)\n",
    "}).set_index('epoch')"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural_Rubik_Train_Data_2.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
