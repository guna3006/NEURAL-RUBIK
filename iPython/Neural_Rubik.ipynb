{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src='../images/fsktm.jpg' width=\"500\" height=\"400\"> </center>\n",
    "# <center> WQD7002 - SCIENCE DATA RESEARCH PROJECT </center>\n",
    "## <center> NEURAL RUBIKâ€™S </center>\n",
    "## <center> Solving Rubik's Cube Using Nueral Network (Hueristic Learning) </center>\n",
    "### <center> Scripted by : Gunasegarran Magadevan (WQD170002) </center>\n",
    "### <center> Supervised by : Dr.Aznul Qalid Md Sabri </center>\n",
    "# <center> <img src=\"../images/RubiksNeural.jpg\" width=\"400\" height=\"300\"> </center>\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# STEP 1 : Installing and upgrading the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Upgrading the pip package to the latest version\n",
    "!python -m pip install --upgrade pip --quiet\n",
    "!python -m pip install PyHamcrest --quiet\n",
    "!python -m pip install tensorflow --quiet\n",
    "\n",
    "\n",
    "#Kindly run tensorflow package manually through terminal or cmd - https://anaconda.org/conda-forge\n",
    "# conda install -c conda-forge tensorflow\n",
    "# conda install -c conda-forge numpy\n",
    "\n",
    "# Installing cubeai - https://pypi.org/project/cubeai\n",
    "## Library for Use Machine Learning to learn a heuristic\n",
    "!python -m pip uninstall cubeai -y --quiet\n",
    "!python -m pip install cubeai --no-cache-dir --upgrade --quiet\n",
    "\n",
    "\n",
    "# Installing seaborn - https://pypi.org/project/cubeai\n",
    "## Library for making statistical graphics in Python.\n",
    "!python -m pip uninstall seaborn -y --quiet\n",
    "!python -m pip install seaborn --no-cache-dir --upgrade --quiet\n",
    "\n",
    "# Installing Keras - https://pypi.org/project/Keras\n",
    "## Library capable of running on top of TensorFlow, CNTK, or Theano.\n",
    "!python -m pip uninstall keras -y --quiet\n",
    "!python -m pip install keras --no-cache-dir --upgrade --quiet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 : Importing the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Importing packages\n",
    "import cubeai as cai                # Cube Modules.\n",
    "import numpy as np                  # To manipulate large multi-dimensional arrays .\n",
    "import pandas as pd                 # To use data structures and data analysis tools.\n",
    "import seaborn as sns               # To create statistical graphics.\n",
    "import matplotlib.pyplot as plt     # To create 2D graphics.\n",
    "import keras                        # High-level neural networks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 : Configurations & Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Configurating for graph plotting - https://seaborn.pydata.org/tutorial/aesthetics.html\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_palette(\"deep\")\n",
    "plt.rcParams.update({'figure.figsize': (10, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# save/load model functions\n",
    "def save_model(model, filename):\n",
    "  global SAVE_TO_DRIVE\n",
    "  if SAVE_TO_DRIVE is True:\n",
    "    model.save(filename)\n",
    "    upload_file_to_drive(filename, filename)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "  return download_model_from_drive(filename, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 4 : Training the module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_features_from_cube(cube):\n",
    "  \"\"\" transforms the cube's array to 1d binary array \"\"\"\n",
    "  binary_array = keras.utils.to_categorical(cube.to_array(), cai.NUM_FACES)\n",
    "  return binary_array.flatten()\n",
    "\n",
    " \n",
    "def data_generator(cube_layers, max_d, batch_size, p=None):\n",
    "  \"\"\"\n",
    "  generates batches of scrambled cubes data, coupled with the number\n",
    "  of scramble moves per row\n",
    "  \"\"\"\n",
    "  new_dim = len(get_features_from_cube(cai.Cube(cube_layers)))\n",
    "  while True:\n",
    "    data = np.empty((batch_size, new_dim), dtype=np.int8)\n",
    "    labels = np.empty(batch_size, dtype=np.int8)\n",
    "    for i in range(batch_size):\n",
    "      c = cai.Cube(cube_layers)\n",
    "      d = np.random.choice(np.arange(max_d+1), p=p)\n",
    "      rand_seq = cai.generate_random_sequence(cube_layers, d)\n",
    "      c.apply(rand_seq)\n",
    "      data[i, :] = get_features_from_cube(c)\n",
    "      labels[i] = d\n",
    "    yield data, labels  \n",
    "\n",
    "\n",
    "def create_dnnregressor(cube_layers, hidden_units, dropout=None,\n",
    "                        optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  creates a fully connected multi-layer perceptron with non-linear activations\n",
    "  to perform regression.\n",
    "  \n",
    "  :param cube_layers: the number of cube layers this model should operate on\n",
    "  :param hidden_units: list of integers specifying how many hidden neurons\n",
    "                       are in each layer\n",
    "  :param dropout: if None, no dropout is used. if a single integer, uses this\n",
    "                  dropout rate after each layer. otherwise, should be a list of\n",
    "                  integers the same length as hidden_units specifying dropout \n",
    "                  rate after each layer\n",
    "  :param optimizer: which (keras) optimizer to use\n",
    "  :param loss: which (keras) loss to use\n",
    "  :returns: a compiled keras.Sequential model\n",
    "  \"\"\"\n",
    "  # input checks\n",
    "  assert hasattr(hidden_units, '__len__'), 'hidden_units must be array-like'\n",
    "  assert len(hidden_units) > 0, 'hidden_units cannot be empty'\n",
    "  if dropout is not None:\n",
    "    if not hasattr(dropout, '__len__'):\n",
    "      dropout = [dropout] * len(hidden_units)\n",
    "    else:\n",
    "      assert len(hidden_units) == len(dropout)\n",
    "  # define some constant model parameters\n",
    "  activation = 'relu'\n",
    "  out_activation = 'relu'\n",
    "  input_dim = len(get_features_from_cube(cai.Cube(cube_layers)))\n",
    "  \n",
    "  # create a sequential model and add the first layer\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Dense(hidden_units[0],\n",
    "                               input_dim=input_dim,\n",
    "                               activation=activation))\n",
    "  if dropout is not None:\n",
    "    model.add(keras.layers.Dropout(dropout[0]))\n",
    "    \n",
    "  # add the rest of the hidden layers\n",
    "  for i in range(1, len(hidden_units)):\n",
    "    model.add(keras.layers.Dense(hidden_units[i], activation=activation))\n",
    "    if dropout is not None:\n",
    "      model.add(keras.layers.Dropout(dropout[i]))\n",
    "\n",
    "  # define the output layer\n",
    "  model.add(keras.layers.Dense(1, activation=out_activation))\n",
    "  model.compile(optimizer=optimizer, loss=loss)\n",
    "  return model\n",
    "\n",
    "\n",
    "def learn_heuristic(layers, max_d, p, steps, epochs, batch_size, hidden_units,\n",
    "                    dropout=None, optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  trains a model with the given config.\n",
    "  \n",
    "  :param layers: number of cube layers\n",
    "  :param max_d: maximum number of scramble steps\n",
    "  :param p: a probability distribution according to which the\n",
    "            scramble steps number is chosen (array of length max_d+1)\n",
    "            (for uniform dist. use None)\n",
    "  :param steps: number of training steps per epoch\n",
    "  :param epochs: number of epochs\n",
    "  :param batch_size: number of cube instances in each training step\n",
    "  :param hidden_units: number of dnn layers and neurons in each layer\n",
    "                       (an array of integers)\n",
    "  :param dropout: same as in create_dnnregressor\n",
    "  :param optimizer: same as in create_dnnregressor\n",
    "  :param loss: same as in create_dnnregressor\n",
    "  :returns: a pair (estimator, history), where estimator is a (trained)\n",
    "            keras model, and history is the training Keras history object\n",
    "  \"\"\"\n",
    "  # set up parameters\n",
    "  c = cai.Cube(layers)\n",
    "  # initialize the model\n",
    "  estimator = create_dnnregressor(\n",
    "      cube_layers=layers,\n",
    "      hidden_units=hidden_units,\n",
    "      dropout=dropout,\n",
    "      optimizer=optimizer,\n",
    "      loss=loss\n",
    "  )\n",
    "  # train the model\n",
    "  history = estimator.fit_generator(\n",
    "      data_generator(layers, max_d, batch_size, p), steps, epochs\n",
    "  )\n",
    "  return estimator, history\n",
    "\n",
    "\n",
    "def model_to_heuristic(model):\n",
    "  \"\"\" creates a heuristic based on the given keras model \"\"\"\n",
    "  \n",
    "  def _model_h(cube, problem=None):\n",
    "    features = get_features_from_cube(cube)\n",
    "    return model.predict(np.reshape(features, (1, -1)))[0][0]\n",
    "  \n",
    "  return _model_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### $3\\times3\\times3$\n",
    "We try different network architectures and see which one performs best.\n",
    "\n",
    "The heuristics are then save in the following format:\n",
    "\n",
    "`<layers>_<max_d>_<hidden_1>_..._<hidden_k>.h5`\n",
    "\n",
    "where `hidden_i` is the number of neurons in the `i`'th hidden layer, and `layers` is the number of layers in the cube, and `max_d` is the maximal number of scramble moves.\n",
    "\n",
    "For example, a $3\\times 3 \\times 3$ model with 3 layers of 50 neurons each, and `max_d=8` is saved as: \n",
    "\"`3_8_50_50_50.h5`\"."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
