{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural Rubik Train Data.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "code",
        "id": "HJcRbEqLgs_I",
        "outputId": "fe23ddc4-4f02-4646-ac2b-b1936f7e4bc5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 46
        }
      },
      "cell_type": "code",
      "source": [
        "!pip install rubikai==0.1.2 --no-cache-dir --upgrade --quiet\n",
        "!pip install seaborn --upgrade --quiet\n",
        "!python -m pip install keras --no-cache-dir --upgrade --quiet\n",
        "\n",
        "import rubikai as rubik\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import seaborn as sns\n",
        "import keras\n",
        "import google.colab.files\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "fvCp8FJlCriL",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "sns.set()\n",
        "sns.set_context(\"talk\")  # larger text\n",
        "sns.set_palette(\"dark\")  # brighter colors\n",
        "plt.rcParams.update({'figure.figsize': (10, 8)})  # bigger figures"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "5zh8X98RQUbw",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# sets up google drive for the model saving/loading\n",
        "!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "v3GIY3i9j8tX",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def refresh_gdrive_token():\n",
        "  global auth\n",
        "  global drive\n",
        "  global gauth\n",
        "  auth.authenticate_user()\n",
        "  gauth = GoogleAuth()\n",
        "  gauth.credentials = GoogleCredentials.get_application_default()\n",
        "  drive = GoogleDrive(gauth)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "swma4dxb_oN-",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "SAVE_TO_DRIVE = True\n",
        "\n",
        "# gdrive stuff\n",
        "def upload_file_to_drive(local_filename, remote_filename=None):\n",
        "  refresh_gdrive_token()\n",
        "  if remote_filename is None:\n",
        "    remote_filename = 'drive_' + local_filename\n",
        "  uploaded = drive.CreateFile({'title': remote_filename})\n",
        "  uploaded.SetContentFile(local_filename)\n",
        "  uploaded.Upload()\n",
        "  return\n",
        "\n",
        "\n",
        "def download_model_from_drive(remote_filename, local_filename=None):\n",
        "  refresh_gdrive_token()\n",
        "  if local_filename is None:\n",
        "    local_filename = 'local_' + remote_filename\n",
        "  file_list = drive.ListFile(\n",
        "      {'q': \"title = '{}'\".format(remote_filename)}).GetList()\n",
        "  if file_list:\n",
        "    file_list[0].GetContentFile(local_filename)\n",
        "    model = keras.models.load_model(local_filename)\n",
        "    return model\n",
        "  else:\n",
        "    print('file not found in drive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "gotiaTw8Zwcj",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# save/load model functions\n",
        "def save_model(model, filename):\n",
        "  global SAVE_TO_DRIVE\n",
        "  if SAVE_TO_DRIVE is True:\n",
        "    model.save(filename)\n",
        "    upload_file_to_drive(filename, filename)\n",
        "    return\n",
        "\n",
        "\n",
        "def load_model(filename):\n",
        "  return download_model_from_drive(filename, filename)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NPRAYU1IuJwF"
      },
      "cell_type": "markdown",
      "source": [
        "## Helper Functions"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "gPSskq2p6zqV"
      },
      "cell_type": "markdown",
      "source": [
        "Below are functions related to probability vectors. \n",
        "* `create_prob_vector` generates the \"real\" distribution of cube configurations\n",
        "* `convex_combination` returns a convex combination of two vectors\n",
        "* `convex_combination_probabilities` returns a convex combination of the real distribution and the uniform one"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "pXvei0SWr9rc",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# number of states in each distance from goal\n",
        "count_vector = np.array([1, 12, 114, 1068, 10011, 93840, 878880, 8221632,\n",
        "                         76843595, 717789576, 6701836858, 62549615248,\n",
        "                         583570100997, 5442351625028, 50729620202582,\n",
        "                         472495678811004, 4393570406220123, 40648181519827392,\n",
        "                         368071526203620348, 3e18, 14e18, 19e18, 7e18, 24e15,\n",
        "                         150000, 36, 3])\n",
        "# (taken from http://cube20.org/qtm/)\n",
        "\n",
        "\n",
        "def create_prob_vector(lower, upper):\n",
        "  vec = count_vector[lower:upper]\n",
        "  return vec / np.sum(vec)\n",
        "\n",
        "\n",
        "def convex_combination(v , u, alpha):\n",
        "  \"\"\" return covex combination of u, v i.e v*alpha + u*(1- alpha) \"\"\"\n",
        "  assert len(u) == len(v), 'u ,v must have same length'\n",
        "  assert 0 <= alpha <= 1, 'alpha must be between 0 and 1'\n",
        "  return np.array(v)*alpha + np.array(u)*(1-alpha)\n",
        "\n",
        "def convex_combination_probabilities(alpha, lower, upper):\n",
        "  \"\"\" \n",
        "  returns convex combination of real probability and uniform distribution\n",
        "  real_probabilites*alpha + uniform*(1- alpha)\n",
        "  \"\"\"\n",
        "  rel_prob = create_prob_vector(lower, upper)\n",
        "  n = len(rel_prob)\n",
        "  uniform = np.ones(n) / n\n",
        "  return convex_combination(rel_prob, uniform, alpha)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "TQCZ4MTz_cFe"
      },
      "cell_type": "markdown",
      "source": [
        "### Functions for Learning"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "u0fLmKLPtUbQ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_features_from_cube(cube):\n",
        "  \"\"\" transforms the cube's array to 1d binary array \"\"\"\n",
        "  binary_array = keras.utils.to_categorical(cube.to_array(), rubik.NUM_FACES)\n",
        "  return binary_array.flatten()\n",
        "\n",
        " \n",
        "def data_generator(cube_layers, max_d, batch_size, p=None):\n",
        "  \"\"\"\n",
        "  generates batches of scrambled cubes data, coupled with the number\n",
        "  of scramble moves per row\n",
        "  \"\"\"\n",
        "  new_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
        "  while True:\n",
        "    data = np.empty((batch_size, new_dim), dtype=np.int8)\n",
        "    labels = np.empty(batch_size, dtype=np.int8)\n",
        "    for i in range(batch_size):\n",
        "      c = rubik.Cube(cube_layers)\n",
        "      d = np.random.choice(np.arange(max_d+1), p=p)\n",
        "      rand_seq = rubik.generate_random_sequence(cube_layers, d)\n",
        "      c.apply(rand_seq)\n",
        "      data[i, :] = get_features_from_cube(c)\n",
        "      labels[i] = d\n",
        "    yield data, labels  \n",
        "\n",
        "\n",
        "def create_dnnregressor(cube_layers, hidden_units, dropout=None,\n",
        "                        optimizer='adagrad', loss='mse'):\n",
        "  \"\"\"\n",
        "  creates a fully connected multi-layer perceptron with non-linear activations\n",
        "  to perform regression.\n",
        "  \n",
        "  :param cube_layers: the number of cube layers this model should operate on\n",
        "  :param hidden_units: list of integers specifying how many hidden neurons\n",
        "                       are in each layer\n",
        "  :param dropout: if None, no dropout is used. if a single integer, uses this\n",
        "                  dropout rate after each layer. otherwise, should be a list of\n",
        "                  integers the same length as hidden_units specifying dropout \n",
        "                  rate after each layer\n",
        "  :param optimizer: which (keras) optimizer to use\n",
        "  :param loss: which (keras) loss to use\n",
        "  :returns: a compiled keras.Sequential model\n",
        "  \"\"\"\n",
        "  # input checks\n",
        "  assert hasattr(hidden_units, '__len__'), 'hidden_units must be array-like'\n",
        "  assert len(hidden_units) > 0, 'hidden_units cannot be empty'\n",
        "  if dropout is not None:\n",
        "    if not hasattr(dropout, '__len__'):\n",
        "      dropout = [dropout] * len(hidden_units)\n",
        "    else:\n",
        "      assert len(hidden_units) == len(dropout)\n",
        "  # define some constant model parameters\n",
        "  activation = 'relu'\n",
        "  out_activation = 'relu'\n",
        "  input_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
        "  \n",
        "  # create a sequential model and add the first layer\n",
        "  model = keras.Sequential()\n",
        "  model.add(keras.layers.Dense(hidden_units[0],\n",
        "                               input_dim=input_dim,\n",
        "                               activation=activation))\n",
        "  if dropout is not None:\n",
        "    model.add(keras.layers.Dropout(dropout[0]))\n",
        "    \n",
        "  # add the rest of the hidden layers\n",
        "  for i in range(1, len(hidden_units)):\n",
        "    model.add(keras.layers.Dense(hidden_units[i], activation=activation))\n",
        "    if dropout is not None:\n",
        "      model.add(keras.layers.Dropout(dropout[i]))\n",
        "\n",
        "  # define the output layer\n",
        "  model.add(keras.layers.Dense(1, activation=out_activation))\n",
        "  model.compile(optimizer=optimizer, loss=loss)\n",
        "  return model\n",
        "\n",
        "\n",
        "def learn_heuristic(layers, max_d, p, steps, epochs, batch_size, hidden_units,\n",
        "                    dropout=None, optimizer='adagrad', loss='mse'):\n",
        "  \"\"\"\n",
        "  trains a model with the given config.\n",
        "  \n",
        "  :param layers: number of cube layers\n",
        "  :param max_d: maximum number of scramble steps\n",
        "  :param p: a probability distribution according to which the\n",
        "            scramble steps number is chosen (array of length max_d+1)\n",
        "            (for uniform dist. use None)\n",
        "  :param steps: number of training steps per epoch\n",
        "  :param epochs: number of epochs\n",
        "  :param batch_size: number of cube instances in each training step\n",
        "  :param hidden_units: number of dnn layers and neurons in each layer\n",
        "                       (an array of integers)\n",
        "  :param dropout: same as in create_dnnregressor\n",
        "  :param optimizer: same as in create_dnnregressor\n",
        "  :param loss: same as in create_dnnregressor\n",
        "  :returns: a pair (estimator, history), where estimator is a (trained)\n",
        "            keras model, and history is the training Keras history object\n",
        "  \"\"\"\n",
        "  # set up parameters\n",
        "  c = rubik.Cube(layers)\n",
        "  # initialize the model\n",
        "  estimator = create_dnnregressor(\n",
        "      cube_layers=layers,\n",
        "      hidden_units=hidden_units,\n",
        "      dropout=dropout,\n",
        "      optimizer=optimizer,\n",
        "      loss=loss\n",
        "  )\n",
        "  # train the model\n",
        "  history = estimator.fit_generator(\n",
        "      data_generator(layers, max_d, batch_size, p), steps, epochs\n",
        "  )\n",
        "  return estimator, history\n",
        "\n",
        "\n",
        "def model_to_heuristic(model):\n",
        "  \"\"\" creates a heuristic based on the given keras model \"\"\"\n",
        "  \n",
        "  def _model_h(cube, problem=None):\n",
        "    features = get_features_from_cube(cube)\n",
        "    return model.predict(np.reshape(features, (1, -1)))[0][0]\n",
        "  \n",
        "  return _model_h"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "oi5RHq-eyWcm"
      },
      "cell_type": "markdown",
      "source": [
        "## $3\\times3\\times3$\n",
        "We try different network architectures and see which one performs best.\n",
        "\n",
        "The heuristics are then save in the following format:\n",
        "\n",
        "`<layers>_<max_d>_<hidden_1>_..._<hidden_k>.h5`\n",
        "\n",
        "where `hidden_i` is the number of neurons in the `i`'th hidden layer, and `layers` is the number of layers in the cube, and `max_d` is the maximal number of scramble moves.\n",
        "\n",
        "For example, a $3\\times 3 \\times 3$ model with 3 layers of 50 neurons each, and `max_d=8` is saved as: \n",
        "\"`3_8_50_50_50.h5`\"."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cE3Kl1ODI3KU",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_model_filename(layers, max_d, hidden_units):\n",
        "  delim = '_'\n",
        "  suffix = '.h5'\n",
        "  return delim.join([str(layers), str(max_d)] + \n",
        "                    [str(h) for h in hidden_units]) + suffix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "HV_K9kv1AYkG"
      },
      "cell_type": "markdown",
      "source": [
        "### $Definations$\n",
        "* `max_d` (maximal number of scramble moves)\n",
        "* `p` (distribution for the number of moves): $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$, where $\\vec \\rho$ is the real distribution of cube configurations, and $\\vec u$ is the unfirom distribution\n",
        "* `steps` (training steps per epoch)\n",
        "* `epochs` (number of epochs)\n",
        "* `batch_size` (number of examples per training step)\n"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "q-u9iYE7FDz9",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "layers = 3\n",
        "max_d = 25\n",
        "p = convex_combination_probabilities(0.1, 0, max_d+1)\n",
        "steps = 100\n",
        "epochs = 100\n",
        "batch_size = 5\n",
        "dropout = None"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FAonOSAtyPJn",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### $\\hat h_1$\n",
        "* `max_d`: `10`\n",
        "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$\n",
        "* `steps`: `100`\n",
        "* `epochs`: `100`\n",
        "* `batch_size`: `8`\n",
        "* Net architecture: \n",
        "  *  3 hidden layers with 70, 60, 50 neurons\n",
        "  * default ReLU activations\n",
        "  * No edge dropout"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "ec0kHJF3Aif2",
        "outputId": "4e6b5e75-5f00-4f3f-ed68-1e1ce50e0010",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3539
        }
      },
      "cell_type": "code",
      "source": [
        "hidden_units_1 = [100, 90, 80]\n",
        "m1, history1 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
        "                               batch_size, hidden_units_1, dropout)\n",
        "save_model(m1, get_model_filename(layers, max_d, hidden_units_1))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Epoch 1/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 38.5335\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 27.7740\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 26.4389\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 45s 449ms/step - loss: 24.0719\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 25.6195\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 25.4414\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 24.2038\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 24.4627\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 24.5355\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 21.7408\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 23.5259\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 19.5880\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 25.2280\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 23.5417\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 51s 507ms/step - loss: 24.5677\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 25.7272\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 23.1081\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 51s 510ms/step - loss: 24.6224\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 46s 464ms/step - loss: 21.4449\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 49s 495ms/step - loss: 21.8238\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 20.7302\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 22.2601\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 20.7874\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 23.2759\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 46s 455ms/step - loss: 23.4473\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 23.7335\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 22.2882\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 21.4378\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 24.6536\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 22.2143\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 24.6507\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 25.1472\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 23.3971\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 23.7377\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 24.0141\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 24.4922\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 21.2216\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 23.8549\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 23.1613\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 24.6168\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 45s 448ms/step - loss: 21.9209\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 20.3484\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 44s 442ms/step - loss: 22.9767\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 44s 435ms/step - loss: 21.2819\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 26.0251\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 22.1965\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 20.9958\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 21.5858\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 22.7669\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 46s 464ms/step - loss: 22.5314\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 44s 441ms/step - loss: 20.2530\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 21.1997\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 21.8155\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 22.2200\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 45s 452ms/step - loss: 19.4792\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 19.3631\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 20.3695\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 43s 431ms/step - loss: 22.0150\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 21.9579\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 45s 446ms/step - loss: 21.1478\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 18.1146\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 20.4197\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 22.5398\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 42s 418ms/step - loss: 21.5392\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 22.9485\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 42s 422ms/step - loss: 20.2200\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 20.6675\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 23.5759\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 20.7506\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 42s 419ms/step - loss: 18.6346\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 44s 445ms/step - loss: 19.6047\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 42s 418ms/step - loss: 19.6387\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 44s 439ms/step - loss: 19.7588\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 45s 452ms/step - loss: 23.2423\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 19.7947\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 43s 427ms/step - loss: 21.7724\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 43s 428ms/step - loss: 21.4091\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 45s 447ms/step - loss: 22.3418\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 42s 418ms/step - loss: 21.2649\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 43s 435ms/step - loss: 21.0998\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 45s 452ms/step - loss: 22.3833\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 44s 436ms/step - loss: 19.9448\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 43s 429ms/step - loss: 21.6214\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 44s 444ms/step - loss: 22.9739\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 45s 447ms/step - loss: 22.0410\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 43s 433ms/step - loss: 21.4554\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 41s 412ms/step - loss: 20.7632\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 21.7098\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 43s 428ms/step - loss: 20.7569\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 44s 439ms/step - loss: 20.5887\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 43s 431ms/step - loss: 21.2412\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 20.5725\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 43s 432ms/step - loss: 21.5537\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 21.1956\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 43s 432ms/step - loss: 21.1388\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 19.5548\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 42s 419ms/step - loss: 19.1458\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 21.6285\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 43s 434ms/step - loss: 18.1175\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 43s 434ms/step - loss: 21.3302\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "8Pi4N14Z91SE"
      },
      "cell_type": "markdown",
      "source": [
        "### $\\hat h_2$\n",
        "* `max_d`: `10`\n",
        "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
        "* `steps`: `100`\n",
        "* `epochs`: `100`\n",
        "* `batch_size`: `8`\n",
        "* Net architecture: \n",
        "  *  4 hidden layers, 50 neurons per layer\n",
        "  * default ReLU activations\n",
        "  * No edge dropout"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Pja05ir-GAhI",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        },
        "outputId": "ce976e69-2fff-4dcd-92ee-fd9299086c81"
      },
      "cell_type": "code",
      "source": [
        "hidden_units_2 = [100, 90, 80, 70]\n",
        "m2, history2 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
        "                               batch_size, hidden_units_2, dropout)\n",
        "save_model(m2, get_model_filename(layers, max_d, hidden_units_2))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 41.5235\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 45s 446ms/step - loss: 27.5651\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 26.7373\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 24.8056\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 25.6253\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 24.0027\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 24.5579\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 25.8435\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 22.4466\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 25.2458\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 23.3096\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 45s 445ms/step - loss: 23.4923\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 45s 448ms/step - loss: 23.0524\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 44s 445ms/step - loss: 22.6571\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 45s 446ms/step - loss: 23.5055\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 47s 475ms/step - loss: 22.7726\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 23.1603\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 46s 465ms/step - loss: 22.9073\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 22.9984\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 21.9708\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 20.5954\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 47s 475ms/step - loss: 21.3297\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 22.2875\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 22.3640\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 21.7959\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 45s 452ms/step - loss: 22.6007\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 19.9685\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 24.3367\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 22.7591\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 46s 464ms/step - loss: 20.7270\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 45s 452ms/step - loss: 24.3790\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 23.2743\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 21.6660\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 22.2376\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 21.4507\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 22.0692\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 22.3354\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 19.1474\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 21.1179\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 22.9291\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 47s 465ms/step - loss: 21.3013\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 43s 429ms/step - loss: 19.9160\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 46s 455ms/step - loss: 23.7911\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 22.8211\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 22.2914\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 21.3211\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 20.9045\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 20.7988\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 44s 435ms/step - loss: 21.7747\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 20.1179\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 22.3008\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 45s 447ms/step - loss: 23.1281\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 22.5607\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 19.7957\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 22.9635\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 21.6289\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 48s 475ms/step - loss: 22.1451\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 44s 442ms/step - loss: 22.9894\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 24.3745\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 20.6367\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 20.9661\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 45s 446ms/step - loss: 21.7559\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 46s 464ms/step - loss: 21.3371\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 45s 447ms/step - loss: 22.2993\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 20.7571\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 45s 448ms/step - loss: 21.7269\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 44s 440ms/step - loss: 21.5268\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 21.6677\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 44s 444ms/step - loss: 20.5613\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 21.0553\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 44s 445ms/step - loss: 24.2074\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 44s 443ms/step - loss: 23.3336\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 45s 449ms/step - loss: 22.5497\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 23.0846\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 22.1596\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 19.7147\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 21.6728\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 20.3690\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 43s 426ms/step - loss: 19.9277\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 20.4119\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 43s 431ms/step - loss: 19.7792\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 23.3522\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 21.2749\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 44s 439ms/step - loss: 22.5103\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 44s 438ms/step - loss: 20.0299\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 44s 435ms/step - loss: 19.5393\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 20.1709\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 43s 431ms/step - loss: 20.6133\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 45s 449ms/step - loss: 20.1782\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 45s 450ms/step - loss: 19.0526\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 45s 454ms/step - loss: 20.7054\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 19.8534\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 18.3854\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 23.4893\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 44s 442ms/step - loss: 19.0784\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 20.8722\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 22.0085\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 21.8874\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 47s 465ms/step - loss: 20.7179\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 44s 437ms/step - loss: 20.8155\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "i2AyPlrIBXOI"
      },
      "cell_type": "markdown",
      "source": [
        "### $\\hat h_3$\n",
        "* `max_d`: `10`\n",
        "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
        "* `steps`: `100`\n",
        "* `epochs`: `100`\n",
        "* `batch_size`: `8`\n",
        "* Net architecture: \n",
        "  *  5 hidden layers with 50, 40, 30, 20, 20 neurons\n",
        "  * default ReLU activations\n",
        "  * No edge dropout"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "E4-bTmMcea2Z",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        },
        "outputId": "a4d32dfb-1ab8-4b74-af18-873c9dc73cda"
      },
      "cell_type": "code",
      "source": [
        "hidden_units_3 = [100, 90, 80, 70, 60]\n",
        "m3, history3 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
        "                               batch_size, hidden_units_3, dropout)\n",
        "save_model(m3, get_model_filename(layers, max_d, hidden_units_3))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 44.8790\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 46s 456ms/step - loss: 25.9845\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 28.4932\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 23.6259\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 52s 517ms/step - loss: 22.4695\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 24.5492\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 60s 603ms/step - loss: 26.4910\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 58s 578ms/step - loss: 21.8769\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 52s 522ms/step - loss: 23.5074\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 58s 585ms/step - loss: 22.7997\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 52s 521ms/step - loss: 25.0385\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 50s 498ms/step - loss: 24.5720\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 24.0172\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 55s 554ms/step - loss: 21.4717\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 58s 577ms/step - loss: 22.7430\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 61s 607ms/step - loss: 22.4270\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 57s 574ms/step - loss: 22.7404\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 60s 600ms/step - loss: 23.6522\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 58s 582ms/step - loss: 24.8936\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 56s 560ms/step - loss: 23.4214\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 50s 504ms/step - loss: 22.5516\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 60s 597ms/step - loss: 22.5810\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 56s 563ms/step - loss: 22.6089\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 51s 507ms/step - loss: 22.1058\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 59s 588ms/step - loss: 22.1682\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 60s 604ms/step - loss: 21.9258\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 22.2800\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 23.2449\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 60s 600ms/step - loss: 21.8522\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 60s 602ms/step - loss: 21.0369\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 61s 606ms/step - loss: 22.6271\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 54s 540ms/step - loss: 24.3253\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 61s 608ms/step - loss: 21.5046\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 54s 536ms/step - loss: 22.9121\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 53s 528ms/step - loss: 22.1130\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 57s 567ms/step - loss: 21.5833\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 57s 569ms/step - loss: 20.6130\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 20.4568\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 60s 605ms/step - loss: 22.6302\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 58s 575ms/step - loss: 23.5324\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 61s 607ms/step - loss: 23.3405\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 58s 578ms/step - loss: 21.0136\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 58s 585ms/step - loss: 21.5883\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 55s 553ms/step - loss: 22.4165\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 56s 561ms/step - loss: 20.8908\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 56s 561ms/step - loss: 22.9811\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 58s 582ms/step - loss: 21.0913\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 59s 592ms/step - loss: 21.7863\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 59s 593ms/step - loss: 24.2875\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 58s 578ms/step - loss: 20.5038\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 57s 571ms/step - loss: 19.2196\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 20.9230\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 55s 550ms/step - loss: 18.9643\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 62s 616ms/step - loss: 20.9035\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 55s 555ms/step - loss: 21.3031\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 57s 573ms/step - loss: 21.4238\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 60s 601ms/step - loss: 23.1051\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 57s 574ms/step - loss: 22.3297\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 70s 698ms/step - loss: 24.0111\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 20.6035\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 22.4460\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 23.4232\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 19.8514\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 21.5667\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 19.9220\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 22.3414\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 50s 498ms/step - loss: 21.7221\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 46s 457ms/step - loss: 20.5018\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 52s 524ms/step - loss: 21.1048\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 22.9029\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 22.3641\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 52s 518ms/step - loss: 20.8548\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 21.3584\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 19.2345\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 21.2378\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 21.6906\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 20.6809\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 20.8170\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 47s 468ms/step - loss: 20.4801\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 22.6833\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 21.0490\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 21.9083\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 54s 542ms/step - loss: 23.0536\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 19.6700\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 50s 502ms/step - loss: 23.4298\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 18.7836\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 19.1428\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 51s 509ms/step - loss: 21.2396\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 20.9082\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 18.4797\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 51s 510ms/step - loss: 16.4677\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 51s 507ms/step - loss: 19.9938\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 50s 502ms/step - loss: 21.3775\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 54s 539ms/step - loss: 19.4966\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 20.6200\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 21.3771\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 19.3124\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 50s 498ms/step - loss: 21.5500\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 55s 549ms/step - loss: 21.1577\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 50s 496ms/step - loss: 21.4095\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Su8wm9ANufaT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### $\\hat h_4$\n",
        "* `max_d`: `10`\n",
        "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
        "* `steps`: `100`\n",
        "* `epochs`: `100`\n",
        "* `batch_size`: `8`\n",
        "* Net architecture: \n",
        "  *  6 hidden layers with 50, 40, 30, 20, 20, 10 neurons\n",
        "  * default ReLU activations\n",
        "  * No edge dropout"
      ]
    },
    {
      "metadata": {
        "id": "xXMAKnPxumHA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        },
        "outputId": "1e1a81b1-3c11-433c-e57e-708260ae78b6"
      },
      "cell_type": "code",
      "source": [
        "hidden_units_4 = [100, 90, 80, 70, 60, 50]\n",
        "m4, history4 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
        "                               batch_size, hidden_units_4, dropout)\n",
        "save_model(m4, get_model_filename(layers, max_d, hidden_units_4))"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 52s 523ms/step - loss: 45.9955\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 50s 504ms/step - loss: 31.0531\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 51s 511ms/step - loss: 24.0012\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 53s 534ms/step - loss: 25.0051\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 25.0706\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 23.4058\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 22.2199\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 22.8796\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 23.3391\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 21.6965\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 23.9002\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 25.5484\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 20.7533\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 23.2148\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 22.9156\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 24.2447\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 23.1214\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 22.3587\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 23.1022\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 24.2844\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 20.4703\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 20.5726\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 22.1846\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 23.1774\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 23.0952\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 50s 504ms/step - loss: 22.7741\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 21.9001\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 23.2182\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 52s 516ms/step - loss: 22.5056\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 23.4843\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 46s 465ms/step - loss: 21.1599\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 22.0405\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 21.0714\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 24.0539\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 20.3352\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 22.1134\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 20.8962\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 20.8979\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 51s 513ms/step - loss: 21.7335\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 22.1052\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 24.0517\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 52s 516ms/step - loss: 22.2591\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 20.1732\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 54s 537ms/step - loss: 22.9281\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 23.5548\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 21.4709\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 21.9041\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 22.5362\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 21.2093\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 23.8457\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 22.6519\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 50s 504ms/step - loss: 22.2568\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 20.4834\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 21.7769\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 50s 502ms/step - loss: 20.3046\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 21.7563\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 51s 508ms/step - loss: 21.7687\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 20.2263\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 19.1629\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 20.8076\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 21.8181\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 21.9013\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 22.9086\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 50s 501ms/step - loss: 20.8601\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 20.2561\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 19.4823\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 21.7436\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 22.4032\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 22.3836\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 19.4777\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 51s 514ms/step - loss: 20.3544\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 22.1447\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 21.4850\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 20.9288\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 51s 511ms/step - loss: 22.9383\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 21.2208\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 21.7254\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 48s 475ms/step - loss: 21.6849\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 22.1013\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 19.9171\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 23.4234\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 20.5968\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 53s 535ms/step - loss: 21.8527\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 47s 475ms/step - loss: 21.8153\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 18.5732\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 20.5144\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 22.3121\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 46s 464ms/step - loss: 22.0997\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 21.3861\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 23.1057\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 18.6582\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 21.8058\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 18.7127\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 22.0334\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 19.1577\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 20.6304\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 21.3272\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 21.0638\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 19.7932\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 21.4732\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "x2jNRLxxvIzw",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### $\\hat h_5$\n",
        "* `max_d`: `10`\n",
        "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
        "* `steps`: `100`\n",
        "* `epochs`: `100`\n",
        "* `batch_size`: `8`\n",
        "* Net architecture: \n",
        "  *  7 hidden layers with 50, 40, 30, 20, 20, 10, 10 neurons\n",
        "  * default ReLU activations\n",
        "  * No edge dropout"
      ]
    },
    {
      "metadata": {
        "id": "crFyGM52vWmK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        },
        "outputId": "8897272e-4d8c-4fb4-dee4-853777e151b7"
      },
      "cell_type": "code",
      "source": [
        "hidden_units_5 = [100, 90, 80, 70, 60, 50, 40]\n",
        "m5, history5 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
        "                               batch_size, hidden_units_5, dropout)\n",
        "save_model(m5, get_model_filename(layers, max_d, hidden_units_5))"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 42.6028\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 50s 499ms/step - loss: 32.6476\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 26.1405\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 44s 444ms/step - loss: 25.0719\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 25.7538\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 25.3955\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 25.4191\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 24.3760\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 24.8090\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 23.6149\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 48s 475ms/step - loss: 23.4174\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 25.4585\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 25.9451\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 22.9864\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 24.0426\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 23.0992\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 21.2396\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 45s 452ms/step - loss: 21.7092\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 45s 449ms/step - loss: 19.8531\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 23.2153\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 23.4145\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 22.1759\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 24.6006\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 46s 464ms/step - loss: 22.6224\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 22.8048\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 23.1899\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 22.4625\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 21.0048\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 21.7726\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 21.8857\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 24.2274\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 23.1063\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 50s 504ms/step - loss: 24.5948\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 50s 495ms/step - loss: 23.0845\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 52s 516ms/step - loss: 24.0283\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 21.6123\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 21.8261\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 24.2844\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 47s 475ms/step - loss: 22.7352\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 51s 510ms/step - loss: 22.7805\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 49s 495ms/step - loss: 22.5686\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 24.4178\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 19.5765\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 18.8270\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 22.4947\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 21.1970\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 45s 451ms/step - loss: 20.3742\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 46s 459ms/step - loss: 19.2725\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 22.3460\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 21.5285\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 23.5600\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 21.5072\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 20.1916\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 23.6231\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 21.9182\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 17.9665\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 22.1435\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 21.4931\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 52s 515ms/step - loss: 22.3294\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 21.8015\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 19.1971\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 20.4532\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 20.3037\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 20.3265\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 49s 491ms/step - loss: 18.4993\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 21.5323\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 20.9290\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 20.7583\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 19.9597\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 20.7285\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 52s 516ms/step - loss: 19.8557\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 20.4821\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 19.6354\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 20.5468\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 19.2666\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 23.0425\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 45s 455ms/step - loss: 20.3800\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 50s 498ms/step - loss: 20.9809\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 22.5192\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 21.0673\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 48s 475ms/step - loss: 21.1535\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 45s 453ms/step - loss: 18.7466\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 21.4058\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 51s 508ms/step - loss: 22.1631\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 51s 511ms/step - loss: 20.9813\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 20.7181\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 21.1591\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 20.0639\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 47s 472ms/step - loss: 19.7292\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 48s 484ms/step - loss: 22.7113\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 21.1378\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 52s 521ms/step - loss: 20.2711\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 50s 502ms/step - loss: 22.1463\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 50s 498ms/step - loss: 19.4046\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 18.2045\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 18.9148\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 45s 452ms/step - loss: 20.5155\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 18.1451\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 46s 463ms/step - loss: 22.9309\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 18.9734\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "3KiHJWEjwJzH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### $\\hat h_6$\n",
        "* `max_d`: `10`\n",
        "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
        "* `steps`: `100`\n",
        "* `epochs`: `100`\n",
        "* `batch_size`: `8`\n",
        "* Net architecture: \n",
        "  *  8 hidden layers with 50, 40, 30, 20, 20, 10, 10 neurons\n",
        "  * default ReLU activations\n",
        "  * No edge dropout"
      ]
    },
    {
      "metadata": {
        "id": "tkzKKC_swJ_P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3417
        },
        "outputId": "4af47f40-8d8d-4237-9b90-4c37f4f8ecca"
      },
      "cell_type": "code",
      "source": [
        "hidden_units_6 = [100, 90, 80, 70, 60, 50, 40, 30]\n",
        "m6, history6 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
        "                               batch_size, hidden_units_6, dropout)\n",
        "save_model(m6, get_model_filename(layers, max_d, hidden_units_6))"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 48.0630\n",
            "Epoch 2/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 28.9524\n",
            "Epoch 3/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 26.8311\n",
            "Epoch 4/100\n",
            "100/100 [==============================] - 49s 493ms/step - loss: 27.1679\n",
            "Epoch 5/100\n",
            "100/100 [==============================] - 62s 621ms/step - loss: 23.5861\n",
            "Epoch 6/100\n",
            "100/100 [==============================] - 60s 596ms/step - loss: 26.2804\n",
            "Epoch 7/100\n",
            "100/100 [==============================] - 51s 508ms/step - loss: 26.3057\n",
            "Epoch 8/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 25.2715\n",
            "Epoch 9/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 25.7223\n",
            "Epoch 10/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 24.3955\n",
            "Epoch 11/100\n",
            "100/100 [==============================] - 51s 508ms/step - loss: 24.6367\n",
            "Epoch 12/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 21.3622\n",
            "Epoch 13/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 23.6476\n",
            "Epoch 14/100\n",
            "100/100 [==============================] - 46s 461ms/step - loss: 22.7512\n",
            "Epoch 15/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 22.7553\n",
            "Epoch 16/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 21.7568\n",
            "Epoch 17/100\n",
            "100/100 [==============================] - 54s 538ms/step - loss: 23.0132\n",
            "Epoch 18/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 23.5004\n",
            "Epoch 19/100\n",
            "100/100 [==============================] - 46s 465ms/step - loss: 23.4049\n",
            "Epoch 20/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 23.2416\n",
            "Epoch 21/100\n",
            "100/100 [==============================] - 49s 486ms/step - loss: 23.5417\n",
            "Epoch 22/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 22.3192\n",
            "Epoch 23/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 23.1265\n",
            "Epoch 24/100\n",
            "100/100 [==============================] - 45s 446ms/step - loss: 22.9851\n",
            "Epoch 25/100\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 21.2663\n",
            "Epoch 26/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 21.8935\n",
            "Epoch 27/100\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 22.4029\n",
            "Epoch 28/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 23.2499\n",
            "Epoch 29/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 21.7784\n",
            "Epoch 30/100\n",
            "100/100 [==============================] - 49s 494ms/step - loss: 21.6281\n",
            "Epoch 31/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 22.4151\n",
            "Epoch 32/100\n",
            "100/100 [==============================] - 45s 449ms/step - loss: 21.1295\n",
            "Epoch 33/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 22.5654\n",
            "Epoch 34/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 19.8813\n",
            "Epoch 35/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 22.7323\n",
            "Epoch 36/100\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 21.7118\n",
            "Epoch 37/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 21.2263\n",
            "Epoch 38/100\n",
            "100/100 [==============================] - 46s 455ms/step - loss: 21.4338\n",
            "Epoch 39/100\n",
            "100/100 [==============================] - 49s 485ms/step - loss: 20.7488\n",
            "Epoch 40/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 21.4046\n",
            "Epoch 41/100\n",
            "100/100 [==============================] - 46s 462ms/step - loss: 21.9289\n",
            "Epoch 42/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 20.4881\n",
            "Epoch 43/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 20.8548\n",
            "Epoch 44/100\n",
            "100/100 [==============================] - 47s 470ms/step - loss: 19.4134\n",
            "Epoch 45/100\n",
            "100/100 [==============================] - 48s 477ms/step - loss: 21.9778\n",
            "Epoch 46/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 21.6079\n",
            "Epoch 47/100\n",
            "100/100 [==============================] - 47s 467ms/step - loss: 19.9465\n",
            "Epoch 48/100\n",
            "100/100 [==============================] - 51s 507ms/step - loss: 22.3651\n",
            "Epoch 49/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 23.8751\n",
            "Epoch 50/100\n",
            "100/100 [==============================] - 46s 458ms/step - loss: 19.8164\n",
            "Epoch 51/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 22.0974\n",
            "Epoch 52/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 22.6575\n",
            "Epoch 53/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 21.1156\n",
            "Epoch 54/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 21.1429\n",
            "Epoch 55/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 20.4428\n",
            "Epoch 56/100\n",
            "100/100 [==============================] - 47s 473ms/step - loss: 21.1995\n",
            "Epoch 57/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 19.9673\n",
            "Epoch 58/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 20.8327\n",
            "Epoch 59/100\n",
            "100/100 [==============================] - 47s 466ms/step - loss: 22.4157\n",
            "Epoch 60/100\n",
            "100/100 [==============================] - 48s 478ms/step - loss: 20.9527\n",
            "Epoch 61/100\n",
            "100/100 [==============================] - 49s 488ms/step - loss: 21.6059\n",
            "Epoch 62/100\n",
            "100/100 [==============================] - 48s 479ms/step - loss: 22.9576\n",
            "Epoch 63/100\n",
            "100/100 [==============================] - 47s 469ms/step - loss: 21.0832\n",
            "Epoch 64/100\n",
            "100/100 [==============================] - 48s 485ms/step - loss: 19.7297\n",
            "Epoch 65/100\n",
            "100/100 [==============================] - 49s 492ms/step - loss: 22.4718\n",
            "Epoch 66/100\n",
            "100/100 [==============================] - 48s 476ms/step - loss: 18.6358\n",
            "Epoch 67/100\n",
            "100/100 [==============================] - 47s 474ms/step - loss: 19.8535\n",
            "Epoch 68/100\n",
            "100/100 [==============================] - 51s 513ms/step - loss: 19.8808\n",
            "Epoch 69/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 19.8360\n",
            "Epoch 70/100\n",
            "100/100 [==============================] - 48s 480ms/step - loss: 19.8935\n",
            "Epoch 71/100\n",
            "100/100 [==============================] - 51s 512ms/step - loss: 20.6246\n",
            "Epoch 72/100\n",
            "100/100 [==============================] - 51s 512ms/step - loss: 21.0307\n",
            "Epoch 73/100\n",
            "100/100 [==============================] - 49s 495ms/step - loss: 21.0186\n",
            "Epoch 74/100\n",
            "100/100 [==============================] - 50s 498ms/step - loss: 18.8065\n",
            "Epoch 75/100\n",
            "100/100 [==============================] - 52s 521ms/step - loss: 20.4758\n",
            "Epoch 76/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 20.6349\n",
            "Epoch 77/100\n",
            "100/100 [==============================] - 50s 505ms/step - loss: 18.7284\n",
            "Epoch 78/100\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 21.1102\n",
            "Epoch 79/100\n",
            "100/100 [==============================] - 49s 495ms/step - loss: 20.2795\n",
            "Epoch 80/100\n",
            "100/100 [==============================] - 49s 489ms/step - loss: 19.2107\n",
            "Epoch 81/100\n",
            "100/100 [==============================] - 50s 500ms/step - loss: 19.9268\n",
            "Epoch 82/100\n",
            "100/100 [==============================] - 50s 497ms/step - loss: 22.1902\n",
            "Epoch 83/100\n",
            "100/100 [==============================] - 52s 520ms/step - loss: 20.7950\n",
            "Epoch 84/100\n",
            "100/100 [==============================] - 48s 483ms/step - loss: 20.4416\n",
            "Epoch 85/100\n",
            "100/100 [==============================] - 48s 481ms/step - loss: 18.9254\n",
            "Epoch 86/100\n",
            "100/100 [==============================] - 50s 499ms/step - loss: 19.5139\n",
            "Epoch 87/100\n",
            "100/100 [==============================] - 51s 505ms/step - loss: 19.2501\n",
            "Epoch 88/100\n",
            "100/100 [==============================] - 49s 490ms/step - loss: 21.4911\n",
            "Epoch 89/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 18.4100\n",
            "Epoch 90/100\n",
            "100/100 [==============================] - 49s 495ms/step - loss: 19.9729\n",
            "Epoch 91/100\n",
            "100/100 [==============================] - 50s 503ms/step - loss: 20.0814\n",
            "Epoch 92/100\n",
            "100/100 [==============================] - 49s 487ms/step - loss: 17.6807\n",
            "Epoch 93/100\n",
            "100/100 [==============================] - 49s 495ms/step - loss: 19.5416\n",
            "Epoch 94/100\n",
            "100/100 [==============================] - 46s 465ms/step - loss: 18.4351\n",
            "Epoch 95/100\n",
            "100/100 [==============================] - 47s 471ms/step - loss: 20.1586\n",
            "Epoch 96/100\n",
            "100/100 [==============================] - 51s 506ms/step - loss: 21.6019\n",
            "Epoch 97/100\n",
            "100/100 [==============================] - 51s 511ms/step - loss: 20.7405\n",
            "Epoch 98/100\n",
            "100/100 [==============================] - 48s 482ms/step - loss: 19.0094\n",
            "Epoch 99/100\n",
            "100/100 [==============================] - 51s 509ms/step - loss: 20.2222\n",
            "Epoch 100/100\n",
            "100/100 [==============================] - 46s 460ms/step - loss: 20.4413\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}