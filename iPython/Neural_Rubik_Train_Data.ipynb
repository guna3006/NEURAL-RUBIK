{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <center> <img src='../images/fsktm.jpg' width=\"500\" height=\"400\"> </center>\n",
    "# <center> WQD7002 - SCIENCE DATA RESEARCH PROJECT </center>\n",
    "## <center> NEURAL RUBIKâ€™S </center>\n",
    "## <center> Solving Rubik's Cube Using Nueral Network (Hueristic Learning) </center>\n",
    "### <center> Scripted by : Gunasegarran Magadevan (WQD170002) </center>\n",
    "### <center> Supervised by : Dr.Aznul Qalid Md Sabri </center>\n",
    "# <center> <img src=\"../images/RubiksNeural.jpg\" width=\"500\" height=\"600\"> </center>\n",
    "----\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 1 : Installing and upgrading the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m-ensorflow 1.11.0 has requirement tensorboard<1.12.0,>=1.11.0, but you'll have tensorboard 1.13.1 which is incompatible.\u001b[0m\r\n"
     ]
    }
   ],
   "source": [
    "# Upgrading the pip package to the latest version\n",
    "!python -m pip install PyHamcrest --upgrade --quiet\n",
    "!python -m pip install tensorflow --upgrade --quiet\n",
    "!python -m pip install rubikai --no-cache-dir --upgrade --quiet\n",
    "!python -m pip install seaborn --no-cache-dir --upgrade --quiet\n",
    "!python -m pip install keras --upgrade --quiet\n",
    "!python -m pip install numpy --upgrade --quiet\n",
    "!pip install -U -q PyDrive\n",
    "\n",
    "# Tensorflow package manually through terminal or cmd - https://anaconda.org/conda-forge\n",
    "#conda install -c conda-forge tensorflow\n",
    "#conda install -c conda-forge numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 2 : Importing the package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-69be1e2f7431>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mseaborn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0msns\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "import rubikai as rubik\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import keras\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### STEP 3 : Import/Export Using Google Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "5zh8X98RQUbw"
   },
   "outputs": [],
   "source": [
    "from pydrive.auth import GoogleAuth\n",
    "from pydrive.drive import GoogleDrive\n",
    "from google.colab import auth\n",
    "from oauth2client.client import GoogleCredentials\n",
    "\n",
    "auth.authenticate_user()\n",
    "gauth = GoogleAuth()\n",
    "gauth.credentials = GoogleCredentials.get_application_default()\n",
    "drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "v3GIY3i9j8tX"
   },
   "outputs": [],
   "source": [
    "def refresh_gdrive_token():\n",
    "  global auth\n",
    "  global drive\n",
    "  global gauth\n",
    "  auth.authenticate_user()\n",
    "  gauth = GoogleAuth()\n",
    "  gauth.credentials = GoogleCredentials.get_application_default()\n",
    "  drive = GoogleDrive(gauth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "swma4dxb_oN-"
   },
   "outputs": [],
   "source": [
    "SAVE_TO_DRIVE = True\n",
    "\n",
    "def upload_file_to_drive(local_filename, remote_filename=None):\n",
    "  refresh_gdrive_token()\n",
    "  if remote_filename is None:\n",
    "    remote_filename = 'drive_' + local_filename\n",
    "  uploaded = drive.CreateFile({'title': remote_filename})\n",
    "  uploaded.SetContentFile(local_filename)\n",
    "  uploaded.Upload()\n",
    "  return\n",
    "\n",
    "\n",
    "def download_model_from_drive(remote_filename, local_filename=None):\n",
    "  refresh_gdrive_token()\n",
    "  if local_filename is None:\n",
    "    local_filename = 'local_' + remote_filename\n",
    "  file_list = drive.ListFile(\n",
    "      {'q': \"title = '{}'\".format(remote_filename)}).GetList()\n",
    "  if file_list:\n",
    "    file_list[0].GetContentFile(local_filename)\n",
    "    model = keras.models.load_model(local_filename)\n",
    "    return model\n",
    "  else:\n",
    "    print('file not found in drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "gotiaTw8Zwcj"
   },
   "outputs": [],
   "source": [
    "# save/load model functions\n",
    "def save_model(model, filename):\n",
    "  global SAVE_TO_DRIVE\n",
    "  if SAVE_TO_DRIVE is True:\n",
    "    model.save(filename)\n",
    "    upload_file_to_drive(filename, filename)\n",
    "    return\n",
    "\n",
    "\n",
    "def load_model(filename):\n",
    "  return download_model_from_drive(filename, filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "NPRAYU1IuJwF"
   },
   "source": [
    "### STEP 4 : Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "gPSskq2p6zqV"
   },
   "source": [
    "Below are functions related to probability vectors. \n",
    "* `create_prob_vector` generates the \"real\" distribution of cube configurations\n",
    "* `convex_combination` returns a convex combination of two vectors\n",
    "* `convex_combination_probabilities` returns a convex combination of the real distribution and the uniform one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "pXvei0SWr9rc"
   },
   "outputs": [],
   "source": [
    "# Number of states in each distance from goal (taken from http://cube20.org/qtm/)\n",
    "count_vector = np.array([1, 12, 114, 1068, 10011, 93840, 878880, 8221632,\n",
    "                         76843595, 717789576, 6701836858, 62549615248,\n",
    "                         583570100997, 5442351625028, 50729620202582,\n",
    "                         472495678811004, 4393570406220123, 40648181519827392,\n",
    "                         368071526203620348, 3e18, 14e18, 19e18, 7e18, 24e15,\n",
    "                         150000, 36, 3])\n",
    "\n",
    "def create_prob_vector(lower, upper):\n",
    "  vec = count_vector[lower:upper]\n",
    "  return vec / np.sum(vec)\n",
    "\n",
    "\n",
    "def convex_combination(v , u, alpha):\n",
    "  \"\"\" return covex combination of u, v i.e v*alpha + u*(1- alpha) \"\"\"\n",
    "  assert len(u) == len(v), 'u ,v must have same length'\n",
    "  assert 0 <= alpha <= 1, 'alpha must be between 0 and 1'\n",
    "  return np.array(v)*alpha + np.array(u)*(1-alpha)\n",
    "\n",
    "def convex_combination_probabilities(alpha, lower, upper):\n",
    "  \"\"\" \n",
    "  returns convex combination of real probability and uniform distribution\n",
    "  real_probabilites*alpha + uniform*(1- alpha)\n",
    "  \"\"\"\n",
    "  rel_prob = create_prob_vector(lower, upper)\n",
    "  n = len(rel_prob)\n",
    "  uniform = np.ones(n) / n\n",
    "  return convex_combination(rel_prob, uniform, alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TQCZ4MTz_cFe"
   },
   "source": [
    "### STEP 5 :  Functions for Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "u0fLmKLPtUbQ"
   },
   "outputs": [],
   "source": [
    "def get_features_from_cube(cube):\n",
    "  \"\"\" transforms the cube's array to 1d binary array \"\"\"\n",
    "  binary_array = keras.utils.to_categorical(cube.to_array(), rubik.NUM_FACES)\n",
    "  return binary_array.flatten()\n",
    "\n",
    " \n",
    "def data_generator(cube_layers, max_d, batch_size, p=None):\n",
    "  \"\"\"\n",
    "  generates batches of scrambled cubes data, coupled with the number\n",
    "  of scramble moves per row\n",
    "  \"\"\"\n",
    "  new_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
    "  while True:\n",
    "    data = np.empty((batch_size, new_dim), dtype=np.int8)\n",
    "    labels = np.empty(batch_size, dtype=np.int8)\n",
    "    for i in range(batch_size):\n",
    "      c = rubik.Cube(cube_layers)\n",
    "      d = np.random.choice(np.arange(max_d+1), p=p)\n",
    "      rand_seq = rubik.generate_random_sequence(cube_layers, d)\n",
    "      c.apply(rand_seq)\n",
    "      data[i, :] = get_features_from_cube(c)\n",
    "      labels[i] = d\n",
    "    yield data, labels  \n",
    "\n",
    "\n",
    "def create_dnnregressor(cube_layers, hidden_units, dropout=None,\n",
    "                        optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  creates a fully connected multi-layer perceptron with non-linear activations\n",
    "  to perform regression.\n",
    "  \n",
    "  :param cube_layers: the number of cube layers this model should operate on\n",
    "  :param hidden_units: list of integers specifying how many hidden neurons\n",
    "                       are in each layer\n",
    "  :param dropout: if None, no dropout is used. if a single integer, uses this\n",
    "                  dropout rate after each layer. otherwise, should be a list of\n",
    "                  integers the same length as hidden_units specifying dropout \n",
    "                  rate after each layer\n",
    "  :param optimizer: which (keras) optimizer to use\n",
    "  :param loss: which (keras) loss to use\n",
    "  :returns: a compiled keras.Sequential model\n",
    "  \"\"\"\n",
    "  # input checks\n",
    "  assert hasattr(hidden_units, '__len__'), 'hidden_units must be array-like'\n",
    "  assert len(hidden_units) > 0, 'hidden_units cannot be empty'\n",
    "  if dropout is not None:\n",
    "    if not hasattr(dropout, '__len__'):\n",
    "      dropout = [dropout] * len(hidden_units)\n",
    "    else:\n",
    "      assert len(hidden_units) == len(dropout)\n",
    "  # define some constant model parameters\n",
    "  activation = 'relu'\n",
    "  out_activation = 'relu'\n",
    "  input_dim = len(get_features_from_cube(rubik.Cube(cube_layers)))\n",
    "  \n",
    "  # create a sequential model and add the first layer\n",
    "  model = keras.Sequential()\n",
    "  model.add(keras.layers.Dense(hidden_units[0],\n",
    "                               input_dim=input_dim,\n",
    "                               activation=activation))\n",
    "  if dropout is not None:\n",
    "    model.add(keras.layers.Dropout(dropout[0]))\n",
    "    \n",
    "  # add the rest of the hidden layers\n",
    "  for i in range(1, len(hidden_units)):\n",
    "    model.add(keras.layers.Dense(hidden_units[i], activation=activation))\n",
    "    if dropout is not None:\n",
    "      model.add(keras.layers.Dropout(dropout[i]))\n",
    "\n",
    "  # define the output layer\n",
    "  model.add(keras.layers.Dense(1, activation=out_activation))\n",
    "  model.compile(optimizer=optimizer, loss=loss)\n",
    "  return model\n",
    "\n",
    "\n",
    "def learn_heuristic(layers, max_d, p, steps, epochs, batch_size, hidden_units,\n",
    "                    dropout=None, optimizer='adagrad', loss='mse'):\n",
    "  \"\"\"\n",
    "  trains a model with the given config.\n",
    "  \n",
    "  :param layers: number of cube layers\n",
    "  :param max_d: maximum number of scramble steps\n",
    "  :param p: a probability distribution according to which the\n",
    "            scramble steps number is chosen (array of length max_d+1)\n",
    "            (for uniform dist. use None)\n",
    "  :param steps: number of training steps per epoch\n",
    "  :param epochs: number of epochs\n",
    "  :param batch_size: number of cube instances in each training step\n",
    "  :param hidden_units: number of dnn layers and neurons in each layer\n",
    "                       (an array of integers)\n",
    "  :param dropout: same as in create_dnnregressor\n",
    "  :param optimizer: same as in create_dnnregressor\n",
    "  :param loss: same as in create_dnnregressor\n",
    "  :returns: a pair (estimator, history), where estimator is a (trained)\n",
    "            keras model, and history is the training Keras history object\n",
    "  \"\"\"\n",
    "  # set up parameters\n",
    "  c = rubik.Cube(layers)\n",
    "  # initialize the model\n",
    "  estimator = create_dnnregressor(\n",
    "      cube_layers=layers,\n",
    "      hidden_units=hidden_units,\n",
    "      dropout=dropout,\n",
    "      optimizer=optimizer,\n",
    "      loss=loss\n",
    "  )\n",
    "  # train the model\n",
    "  history = estimator.fit_generator(\n",
    "      data_generator(layers, max_d, batch_size, p), steps, epochs\n",
    "  )\n",
    "  return estimator, history\n",
    "\n",
    "\n",
    "def model_to_heuristic(model):\n",
    "  \"\"\" creates a heuristic based on the given keras model \"\"\"\n",
    "  \n",
    "  def _model_h(cube, problem=None):\n",
    "    features = get_features_from_cube(cube)\n",
    "    return model.predict(np.reshape(features, (1, -1)))[0][0]\n",
    "  \n",
    "  return _model_h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "oi5RHq-eyWcm"
   },
   "source": [
    "### STEP 6 :  Functions for Training\n",
    "\n",
    "#### $3\\times3\\times3$\n",
    "We try different network architectures and see which one performs best.\n",
    "\n",
    "The heuristics are then save in the following format:\n",
    "\n",
    "`<layers>_<max_d>_<hidden_1>_..._<hidden_k>.h5`\n",
    "\n",
    "where `hidden_i` is the number of neurons in the `i`'th hidden layer, and `layers` is the number of layers in the cube, and `max_d` is the maximal number of scramble moves.\n",
    "\n",
    "For example, a $3\\times 3 \\times 3$ model with 3 layers of 50 neurons each, and `max_d=8` is saved as: \n",
    "\"`3_8_50_50_50.h5`\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "cE3Kl1ODI3KU"
   },
   "outputs": [],
   "source": [
    "def get_model_filename(layers, max_d, hidden_units):\n",
    "  delim = '_'\n",
    "  suffix = '.h5'\n",
    "  return delim.join([str(layers), str(max_d)] + \n",
    "                    [str(h) for h in hidden_units]) + suffix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HV_K9kv1AYkG"
   },
   "source": [
    "### $Definations$\n",
    "* `max_d` (maximal number of scramble moves)\n",
    "* `p` (distribution for the number of moves): $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$, where $\\vec \\rho$ is the real distribution of cube configurations, and $\\vec u$ is the unfirom distribution\n",
    "* `steps` (training steps per epoch)\n",
    "* `epochs` (number of epochs)\n",
    "* `batch_size` (number of examples per training step)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "collapsed": true,
    "id": "q-u9iYE7FDz9"
   },
   "outputs": [],
   "source": [
    "layers = 3\n",
    "max_d = 25\n",
    "p = convex_combination_probabilities(0.1, 0, max_d+1)\n",
    "steps = 100\n",
    "epochs = 100\n",
    "batch_size = 5\n",
    "dropout = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FAonOSAtyPJn"
   },
   "source": [
    "### $\\hat h_1$\n",
    "* `max_d`: `10`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$\n",
    "* `steps`: `100`\n",
    "* `epochs`: `100`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  3 hidden layers with 100, 90, 80 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3539
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "ec0kHJF3Aif2",
    "outputId": "4e6b5e75-5f00-4f3f-ed68-1e1ce50e0010"
   },
   "outputs": [],
   "source": [
    "hidden_units_1 = [100, 90, 80]\n",
    "m1, history1 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_1, dropout)\n",
    "save_model(m1, get_model_filename(layers, max_d, hidden_units_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "8Pi4N14Z91SE"
   },
   "source": [
    "### $\\hat h_2$\n",
    "* `max_d`: `10`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
    "* `steps`: `100`\n",
    "* `epochs`: `100`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  4 hidden layers with 100, 90, 80, 70 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "Pja05ir-GAhI",
    "outputId": "ce976e69-2fff-4dcd-92ee-fd9299086c81"
   },
   "outputs": [],
   "source": [
    "hidden_units_2 = [100, 90, 80, 70]\n",
    "m2, history2 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_2, dropout)\n",
    "save_model(m2, get_model_filename(layers, max_d, hidden_units_2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "i2AyPlrIBXOI"
   },
   "source": [
    "### $\\hat h_3$\n",
    "* `max_d`: `10`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
    "* `steps`: `100`\n",
    "* `epochs`: `100`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  5 hidden layers with 100, 90, 80, 70, 60 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "E4-bTmMcea2Z",
    "outputId": "a4d32dfb-1ab8-4b74-af18-873c9dc73cda"
   },
   "outputs": [],
   "source": [
    "hidden_units_3 = [100, 90, 80, 70, 60]\n",
    "m3, history3 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_3, dropout)\n",
    "save_model(m3, get_model_filename(layers, max_d, hidden_units_3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "Su8wm9ANufaT"
   },
   "source": [
    "### $\\hat h_4$\n",
    "* `max_d`: `10`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
    "* `steps`: `100`\n",
    "* `epochs`: `100`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  6 hidden layers with 10, 90, 80, 70, 60, 50 neurons neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "xXMAKnPxumHA",
    "outputId": "1e1a81b1-3c11-433c-e57e-708260ae78b6"
   },
   "outputs": [],
   "source": [
    "hidden_units_4 = [100, 90, 80, 70, 60, 50]\n",
    "m4, history4 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_4, dropout)\n",
    "save_model(m4, get_model_filename(layers, max_d, hidden_units_4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "x2jNRLxxvIzw"
   },
   "source": [
    "### $\\hat h_5$\n",
    "* `max_d`: `10`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
    "* `steps`: `100`\n",
    "* `epochs`: `100`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  7 hidden layers with 100, 90, 80, 70, 60, 50, 40 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "crFyGM52vWmK",
    "outputId": "8897272e-4d8c-4fb4-dee4-853777e151b7"
   },
   "outputs": [],
   "source": [
    "hidden_units_5 = [100, 90, 80, 70, 60, 50, 40]\n",
    "m5, history5 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_5, dropout)\n",
    "save_model(m5, get_model_filename(layers, max_d, hidden_units_5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3KiHJWEjwJzH"
   },
   "source": [
    "### $\\hat h_6$\n",
    "* `max_d`: `10`\n",
    "* `p`: $0.1 \\cdot \\vec \\rho + 0.9 \\cdot \\vec u$ (same as in $\\hat h_1$)\n",
    "* `steps`: `100`\n",
    "* `epochs`: `100`\n",
    "* `batch_size`: `8`\n",
    "* Net architecture: \n",
    "  *  8 hidden layers with 100, 90, 80, 70, 60, 50, 40, 30 neurons\n",
    "  * default ReLU activations\n",
    "  * No edge dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 3417
    },
    "colab_type": "code",
    "collapsed": true,
    "id": "tkzKKC_swJ_P",
    "outputId": "4af47f40-8d8d-4237-9b90-4c37f4f8ecca"
   },
   "outputs": [],
   "source": [
    "hidden_units_6 = [100, 90, 80, 70, 60, 50, 40, 30]\n",
    "m6, history6 = learn_heuristic(layers, max_d, p, steps, epochs,\n",
    "                               batch_size, hidden_units_6, dropout)\n",
    "save_model(m6, get_model_filename(layers, max_d, hidden_units_6))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Neural Rubik Train Data.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
